"""CLI ì¸í„°í˜ì´ìŠ¤."""

import argparse
import json
import logging
import os
import shutil
import sys
import tempfile
from dataclasses import dataclass
from pathlib import Path

from tubearchive.core.detector import detect_metadata
from tubearchive.core.merger import Merger
from tubearchive.core.scanner import scan_videos
from tubearchive.core.transcoder import Transcoder
from tubearchive.database.repository import MergeJobRepository
from tubearchive.database.schema import init_database
from tubearchive.utils.progress import MultiProgressBar

logger = logging.getLogger(__name__)

# í™˜ê²½ ë³€ìˆ˜
ENV_OUTPUT_DIR = "TUBEARCHIVE_OUTPUT_DIR"


def get_default_output_dir() -> Path | None:
    """í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê¸°ë³¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ ê°€ì ¸ì˜¤ê¸°."""
    env_dir = os.environ.get(ENV_OUTPUT_DIR)
    if env_dir:
        path = Path(env_dir)
        if path.is_dir():
            return path
        logger.warning(f"{ENV_OUTPUT_DIR}={env_dir} is not a valid directory")
    return None


def get_temp_dir() -> Path:
    """ì‹œìŠ¤í…œ ì„ì‹œ ë””ë ‰í† ë¦¬ ë‚´ tubearchive í´ë” ë°˜í™˜."""
    temp_base = Path(tempfile.gettempdir()) / "tubearchive"
    temp_base.mkdir(exist_ok=True)
    return temp_base


def check_output_disk_space(output_dir: Path, required_bytes: int) -> bool:
    """
    ì¶œë ¥ ë””ë ‰í† ë¦¬ ë””ìŠ¤í¬ ê³µê°„ í™•ì¸.

    Args:
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        required_bytes: í•„ìš”í•œ ë°”ì´íŠ¸ ìˆ˜

    Returns:
        ê³µê°„ì´ ì¶©ë¶„í•˜ë©´ True
    """
    usage = shutil.disk_usage(output_dir)
    if usage.free < required_bytes:
        logger.warning(
            f"Insufficient disk space: {usage.free / (1024**3):.1f}GB available, "
            f"{required_bytes / (1024**3):.1f}GB required"
        )
        return False
    return True


@dataclass
class ValidatedArgs:
    """ê²€ì¦ëœ CLI ì¸ì."""

    targets: list[Path]
    output: Path | None
    output_dir: Path | None
    no_resume: bool
    keep_temp: bool
    dry_run: bool
    upload: bool = False


def create_parser() -> argparse.ArgumentParser:
    """
    CLI íŒŒì„œ ìƒì„±.

    Returns:
        argparse.ArgumentParser ì¸ìŠ¤í„´ìŠ¤
    """
    parser = argparse.ArgumentParser(
        prog="tubearchive",
        description="ë‹¤ì–‘í•œ ê¸°ê¸°ì˜ 4K ì˜ìƒì„ í‘œì¤€í™”í•˜ì—¬ ë³‘í•©í•©ë‹ˆë‹¤.",
        epilog=(
            "ì˜ˆì‹œ:\n"
            "  tubearchive video1.mp4 video2.mov -o merged.mp4  # ë³‘í•©\n"
            "  tubearchive ~/Videos/ --upload                   # ë³‘í•© í›„ ì—…ë¡œë“œ\n"
            "  tubearchive --upload-only merged.mp4             # ì—…ë¡œë“œë§Œ"
        ),
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )

    parser.add_argument(
        "targets",
        nargs="*",
        default=[],
        help="ì˜ìƒ íŒŒì¼ ë˜ëŠ” ë””ë ‰í† ë¦¬ (ê¸°ë³¸: í˜„ì¬ ë””ë ‰í† ë¦¬)",
    )

    parser.add_argument(
        "-o", "--output",
        type=str,
        default=None,
        help="ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸: merged_output.mp4)",
    )

    parser.add_argument(
        "--no-resume",
        action="store_true",
        help="Resume ê¸°ëŠ¥ ë¹„í™œì„±í™”",
    )

    parser.add_argument(
        "--keep-temp",
        action="store_true",
        help="ì„ì‹œ íŒŒì¼ ë³´ì¡´ (ë””ë²„ê¹…ìš©)",
    )

    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ì‹¤í–‰ ê³„íšë§Œ ì¶œë ¥ (ì‹¤ì œ ì‹¤í–‰ ì•ˆ í•¨)",
    )

    parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥",
    )

    parser.add_argument(
        "--output-dir",
        type=str,
        default=None,
        help=f"ì¶œë ¥ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬ (í™˜ê²½ë³€ìˆ˜: {ENV_OUTPUT_DIR})",
    )

    # YouTube ì—…ë¡œë“œ ì˜µì…˜
    parser.add_argument(
        "--upload",
        action="store_true",
        help="ë³‘í•© ì™„ë£Œ í›„ YouTubeì— ì—…ë¡œë“œ",
    )

    parser.add_argument(
        "--upload-only",
        type=str,
        metavar="FILE",
        default=None,
        help="ì§€ì •ëœ íŒŒì¼ì„ YouTubeì— ì—…ë¡œë“œ (ë³‘í•© ì—†ì´)",
    )

    parser.add_argument(
        "--upload-title",
        type=str,
        default=None,
        help="YouTube ì—…ë¡œë“œ ì‹œ ì˜ìƒ ì œëª© (ê¸°ë³¸: íŒŒì¼ëª…)",
    )

    parser.add_argument(
        "--upload-privacy",
        type=str,
        default="unlisted",
        choices=["public", "unlisted", "private"],
        help="YouTube ê³µê°œ ì„¤ì • (ê¸°ë³¸: unlisted)",
    )

    parser.add_argument(
        "--setup-youtube",
        action="store_true",
        help="YouTube ì¸ì¦ ìƒíƒœ í™•ì¸ ë° ì„¤ì • ê°€ì´ë“œ ì¶œë ¥",
    )

    return parser


def validate_args(args: argparse.Namespace) -> ValidatedArgs:
    """
    CLI ì¸ì ê²€ì¦.

    Args:
        args: íŒŒì‹±ëœ ì¸ì

    Returns:
        ê²€ì¦ëœ ì¸ì

    Raises:
        FileNotFoundError: íŒŒì¼/ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°
    """
    # targets ê²€ì¦
    targets: list[Path] = []
    if not args.targets:
        targets = [Path.cwd()]
    else:
        for target in args.targets:
            path = Path(target)
            if not path.exists():
                raise FileNotFoundError(f"Target not found: {target}")
            targets.append(path)

    # output ê²€ì¦
    output: Path | None = None
    if args.output:
        output = Path(args.output)
        if not output.parent.exists():
            raise FileNotFoundError(f"Output directory not found: {output.parent}")

    # output_dir ê²€ì¦ (CLI ì¸ì > í™˜ê²½ ë³€ìˆ˜ > None)
    output_dir: Path | None = None
    if args.output_dir:
        output_dir = Path(args.output_dir)
        if not output_dir.is_dir():
            raise FileNotFoundError(f"Output directory not found: {args.output_dir}")
    else:
        output_dir = get_default_output_dir()

    # upload í”Œë˜ê·¸ í™•ì¸
    upload = getattr(args, "upload", False)

    return ValidatedArgs(
        targets=targets,
        output=output,
        output_dir=output_dir,
        no_resume=args.no_resume,
        keep_temp=args.keep_temp,
        dry_run=args.dry_run,
        upload=upload,
    )


def setup_logging(verbose: bool = False) -> None:
    """
    ë¡œê¹… ì„¤ì •.

    Args:
        verbose: ìƒì„¸ ë¡œê·¸ ì—¬ë¶€
    """
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
    )


def get_output_filename(targets: list[Path]) -> str:
    """
    ì…ë ¥ íƒ€ê²Ÿì—ì„œ ì¶œë ¥ íŒŒì¼ëª… ìƒì„±.

    ë””ë ‰í† ë¦¬ëª… ë˜ëŠ” ì²« ë²ˆì§¸ íŒŒì¼ì˜ ë¶€ëª¨ ë””ë ‰í† ë¦¬ëª…ì„ ì‚¬ìš©.

    Args:
        targets: ì…ë ¥ íƒ€ê²Ÿ ëª©ë¡

    Returns:
        ì¶œë ¥ íŒŒì¼ëª… (í™•ì¥ì í¬í•¨)
    """
    if not targets:
        return "output.mp4"

    first_target = targets[0]
    if first_target.is_dir():
        # ë””ë ‰í† ë¦¬ë©´ ë””ë ‰í† ë¦¬ëª… ì‚¬ìš©
        name = first_target.name
    else:
        # íŒŒì¼ì´ë©´ ë¶€ëª¨ ë””ë ‰í† ë¦¬ëª… ì‚¬ìš©
        name = first_target.parent.name

    # ë¹ˆ ì´ë¦„ì´ê±°ë‚˜ í˜„ì¬ ë””ë ‰í† ë¦¬ë©´ ê¸°ë³¸ê°’
    if not name or name == ".":
        name = "output"

    return f"{name}.mp4"


def run_pipeline(validated_args: ValidatedArgs) -> Path:
    """
    ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰.

    Args:
        validated_args: ê²€ì¦ëœ ì¸ì

    Returns:
        ìµœì¢… ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    """
    # 1. íŒŒì¼ ìŠ¤ìº”
    logger.info("Scanning video files...")
    video_files = scan_videos(validated_args.targets)

    if not video_files:
        logger.error("No video files found")
        raise ValueError("No video files found")

    logger.info(f"Found {len(video_files)} video files")
    for vf in video_files:
        logger.info(f"  - {vf.path.name}")

    # 2. íŠ¸ëœìŠ¤ì½”ë”© (ì„ì‹œ íŒŒì¼ì€ /tmpì— ì €ì¥)
    temp_dir = get_temp_dir()
    logger.info(f"Using temp directory: {temp_dir}")
    logger.info("Starting transcoding...")
    transcoded_paths: list[Path] = []
    # (íŒŒì¼ëª…, duration, device_model, creation_time_str)
    video_clips: list[tuple[str, float, str | None, str | None]] = []
    progress = MultiProgressBar(total_files=len(video_files))

    with Transcoder(temp_dir=temp_dir) as transcoder:
        for vf in video_files:
            progress.start_file(vf.path.name)

            def on_progress(percent: int) -> None:
                progress.update_file_progress(percent)

            output_path = transcoder.transcode_video(vf)
            transcoded_paths.append(output_path)

            # ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ (Summaryìš©)
            try:
                metadata = detect_metadata(vf.path)
                creation_time_str = vf.creation_time.strftime("%H:%M:%S")
                video_clips.append((
                    vf.path.name,
                    metadata.duration_seconds,
                    metadata.device_model,
                    creation_time_str,
                ))
            except Exception as e:
                logger.warning(f"Failed to get metadata for {vf.path}: {e}")
                video_clips.append((vf.path.name, 0.0, None, None))

            progress.finish_file()

    # 3. ë³‘í•©
    logger.info("Merging videos...")

    # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ê²°ì •
    if validated_args.output:
        output_path = validated_args.output
    else:
        output_filename = get_output_filename(validated_args.targets)
        output_dir = validated_args.output_dir or Path.cwd()
        output_path = output_dir / output_filename

    merger = Merger(temp_dir=temp_dir)
    final_path = merger.merge(transcoded_paths, output_path)

    logger.info(f"Final output: {final_path}")

    # 4. DBì— íƒ€ì„ë¼ì¸ ì •ë³´ ì €ì¥ ë° Summary ìƒì„±
    summary_markdown = save_merge_job_to_db(
        final_path, video_clips, validated_args.targets
    )

    # 5. ì„ì‹œ íŒŒì¼ ë° í´ë” ì •ë¦¬
    if not validated_args.keep_temp:
        logger.info("Cleaning up temporary files...")
        for temp_path in transcoded_paths:
            if temp_path.exists() and temp_path != final_path:
                temp_path.unlink()
                logger.debug(f"  Removed: {temp_path}")

        # ì„ì‹œ í´ë” ì‚­ì œ (ë¹„ì–´ìˆê±°ë‚˜ concat íŒŒì¼ë§Œ ë‚¨ì€ ê²½ìš°)
        if temp_dir.exists():
            try:
                shutil.rmtree(temp_dir)
                logger.info(f"Removed temp directory: {temp_dir}")
            except OSError as e:
                logger.warning(f"Failed to remove temp directory: {e}")

    # 6. Summary ì¶œë ¥ (ë³µì‚¬í•´ì„œ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥)
    if summary_markdown:
        print("\n" + "=" * 60)
        print("ğŸ“‹ SUMMARY (Copy & Paste)")
        print("=" * 60)
        print(summary_markdown)
        print("=" * 60 + "\n")

    return final_path


def save_merge_job_to_db(
    output_path: Path,
    video_clips: list[tuple[str, float, str | None, str | None]],
    targets: list[Path],
) -> str | None:
    """
    ë³‘í•© ì‘ì—… ì •ë³´ë¥¼ DBì— ì €ì¥ (íƒ€ì„ë¼ì¸ ë° Summary í¬í•¨).

    Args:
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        video_clips: (íŒŒì¼ëª…, ì¬ìƒì‹œê°„, ê¸°ì¢…, ì´¬ì˜ì‹œê°„) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        targets: ì…ë ¥ íƒ€ê²Ÿ ëª©ë¡ (ì œëª© ì¶”ì¶œìš©)

    Returns:
        ìƒì„±ëœ Summary ë§ˆí¬ë‹¤ìš´ (ì‹¤íŒ¨ ì‹œ None)
    """
    from tubearchive.utils.summary_generator import generate_clip_summary

    try:
        conn = init_database()
        repo = MergeJobRepository(conn)

        # íƒ€ì„ë¼ì¸ ì •ë³´ ìƒì„± (ê° í´ë¦½ì˜ ë©”íƒ€ë°ì´í„° í¬í•¨)
        timeline: list[dict[str, str | float | None]] = []
        current_time = 0.0
        for name, duration, device, shot_time in video_clips:
            timeline.append({
                "name": name,
                "duration": duration,
                "start": current_time,
                "end": current_time + duration,
                "device": device,
                "shot_time": shot_time,
            })
            current_time += duration

        clips_json = json.dumps(timeline, ensure_ascii=False)

        # ì œëª©: ë””ë ‰í† ë¦¬ëª…
        title = None
        if targets:
            first_target = targets[0]
            if first_target.is_dir():
                title = first_target.name
            else:
                title = first_target.parent.name
            if not title or title == ".":
                title = output_path.stem

        # ë‚ ì§œ: ì˜¤ëŠ˜
        from datetime import date
        today = date.today().isoformat()

        # ì´ ì¬ìƒì‹œê°„ ë° íŒŒì¼ í¬ê¸°
        total_duration = sum(d for _, d, _, _ in video_clips)
        total_size = output_path.stat().st_size if output_path.exists() else 0

        # Summary ë§ˆí¬ë‹¤ìš´ ìƒì„± (ê¸°ì¢…, ì´¬ì˜ì‹œê°„, íƒ€ì„ìŠ¤íƒ¬í”„)
        summary_markdown = generate_clip_summary(video_clips)

        repo.create(
            output_path=output_path,
            video_ids=[],
            title=title,
            date=today,
            total_duration_seconds=total_duration,
            total_size_bytes=total_size,
            clips_info_json=clips_json,
            summary_markdown=summary_markdown,
        )
        conn.close()
        logger.debug("Merge job saved to database with summary")
        return summary_markdown

    except Exception as e:
        logger.warning(f"Failed to save merge job to DB: {e}")
        return None


def upload_to_youtube(
    file_path: Path,
    title: str | None = None,
    description: str = "",
    privacy: str = "unlisted",
    merge_job_id: int | None = None,
) -> None:
    """
    ì˜ìƒì„ YouTubeì— ì—…ë¡œë“œ.

    Args:
        file_path: ì—…ë¡œë“œí•  ì˜ìƒ íŒŒì¼ ê²½ë¡œ
        title: ì˜ìƒ ì œëª© (Noneì´ë©´ íŒŒì¼ëª… ì‚¬ìš©)
        description: ì˜ìƒ ì„¤ëª…
        privacy: ê³µê°œ ì„¤ì • (public, unlisted, private)
        merge_job_id: DBì— ì €ì¥í•  MergeJob ID
    """
    from tubearchive.youtube.auth import YouTubeAuthError, get_authenticated_service
    from tubearchive.youtube.uploader import YouTubeUploader, YouTubeUploadError

    if not file_path.exists():
        raise FileNotFoundError(f"Video file not found: {file_path}")

    # ì œëª© ê²°ì •: ì§€ì •ê°’ > íŒŒì¼ëª…(í™•ì¥ì ì œì™¸)
    video_title = title or file_path.stem

    logger.info(f"Uploading to YouTube: {file_path}")
    logger.info(f"  Title: {video_title}")
    logger.info(f"  Privacy: {privacy}")

    try:
        # ì¸ì¦
        service = get_authenticated_service()

        # ì—…ë¡œë“œ
        uploader = YouTubeUploader(service)

        def on_progress(percent: int) -> None:
            logger.info(f"Upload progress: {percent}%")

        result = uploader.upload(
            file_path=file_path,
            title=video_title,
            description=description,
            privacy=privacy,
            on_progress=on_progress,
        )

        print("\nâœ… YouTube ì—…ë¡œë“œ ì™„ë£Œ!")
        print(f"ğŸ¬ URL: {result.url}")

        # DBì— YouTube ID ì €ì¥
        if merge_job_id is not None:
            try:
                conn = init_database()
                repo = MergeJobRepository(conn)
                repo.update_youtube_id(merge_job_id, result.video_id)
                conn.close()
                logger.debug(f"YouTube ID {result.video_id} saved to merge job {merge_job_id}")
            except Exception as e:
                logger.warning(f"Failed to save YouTube ID to DB: {e}")

    except YouTubeAuthError as e:
        logger.error(f"YouTube authentication failed: {e}")
        print(f"\nâŒ YouTube ì¸ì¦ ì‹¤íŒ¨: {e}")
        raise
    except YouTubeUploadError as e:
        logger.error(f"YouTube upload failed: {e}")
        print(f"\nâŒ YouTube ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise


def cmd_setup_youtube() -> None:
    """
    --setup-youtube ì˜µì…˜ ì²˜ë¦¬.

    YouTube ì¸ì¦ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ì„¤ì • ê°€ì´ë“œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    from tubearchive.youtube.auth import check_auth_status

    print("\nğŸ¬ YouTube ì—…ë¡œë“œ ì„¤ì • ìƒíƒœ\n")
    print("=" * 50)

    status = check_auth_status()
    print(status.get_setup_guide())

    print("=" * 50)

    # ë¸Œë¼ìš°ì € ì¸ì¦ì´ í•„ìš”í•˜ë©´ ë°”ë¡œ ì‹¤í–‰ ì œì•ˆ
    if status.needs_browser_auth:
        print("\nğŸ’¡ ì§€ê¸ˆ ë°”ë¡œ ì¸ì¦í•˜ë ¤ë©´:")
        print("   tubearchive --upload-only <ì˜ìƒíŒŒì¼>")
        print("   (ë¸Œë¼ìš°ì €ê°€ ì—´ë¦¬ë©° Google ê³„ì • ì¸ì¦ì´ ì§„í–‰ë©ë‹ˆë‹¤)")


def cmd_upload_only(args: argparse.Namespace) -> None:
    """
    --upload-only ì˜µì…˜ ì²˜ë¦¬.

    Args:
        args: íŒŒì‹±ëœ ì¸ì
    """
    file_path = Path(args.upload_only)

    if not file_path.exists():
        logger.error(f"File not found: {file_path}")
        sys.exit(1)

    # DBì—ì„œ MergeJob ì¡°íšŒ (ê²½ë¡œë¡œ ì°¾ê¸°)
    merge_job_id = None
    description = ""

    try:
        conn = init_database()

        # ìµœì‹  MergeJobì—ì„œ ì¼ì¹˜í•˜ëŠ” ê²½ë¡œ ì°¾ê¸°
        cursor = conn.execute(
            """SELECT id, summary_markdown FROM merge_jobs
            WHERE output_path = ? ORDER BY created_at DESC LIMIT 1""",
            (str(file_path),),
        )
        row = cursor.fetchone()
        if row:
            merge_job_id = row["id"]
            # descriptionì´ ë¹„ì–´ìˆìœ¼ë©´ summary_markdown ì‚¬ìš©
            if row["summary_markdown"]:
                description = row["summary_markdown"]
                logger.info("Using summary from database as description")

        conn.close()
    except Exception as e:
        logger.warning(f"Failed to load merge job from DB: {e}")

    # ì—…ë¡œë“œ ì‹¤í–‰
    upload_to_youtube(
        file_path=file_path,
        title=args.upload_title,
        description=description,
        privacy=args.upload_privacy,
        merge_job_id=merge_job_id,
    )


def main() -> None:
    """CLI ì§„ì…ì ."""
    parser = create_parser()
    args = parser.parse_args()

    setup_logging(args.verbose)

    try:
        # --setup-youtube ì˜µì…˜ ì²˜ë¦¬ (ì„¤ì • ê°€ì´ë“œ)
        if args.setup_youtube:
            cmd_setup_youtube()
            return

        # --upload-only ì˜µì…˜ ì²˜ë¦¬ (ì—…ë¡œë“œë§Œ)
        if args.upload_only:
            cmd_upload_only(args)
            return

        validated_args = validate_args(args)

        if validated_args.dry_run:
            # Dry run: ì‹¤í–‰ ê³„íšë§Œ ì¶œë ¥
            logger.info("Dry run mode - showing execution plan only")

            video_files = scan_videos(validated_args.targets)
            temp_dir = get_temp_dir()

            # ì¶œë ¥ ê²½ë¡œ ê³„ì‚°
            if validated_args.output:
                output_str = str(validated_args.output)
            else:
                output_filename = get_output_filename(validated_args.targets)
                output_dir = validated_args.output_dir or Path.cwd()
                output_str = str(output_dir / output_filename)

            print("\n=== Dry Run Execution Plan ===")
            print(f"Input targets: {[str(t) for t in validated_args.targets]}")
            print(f"Video files found: {len(video_files)}")
            for vf in video_files:
                print(f"  - {vf.path}")
            print(f"Output: {output_str}")
            print(f"Temp dir: {temp_dir}")
            print(f"Resume enabled: {not validated_args.no_resume}")
            print(f"Keep temp files: {validated_args.keep_temp}")
            print("=" * 30)
            return

        output_path = run_pipeline(validated_args)
        print("\nâœ… ì™„ë£Œ!")
        print(f"ğŸ“¹ ì¶œë ¥ íŒŒì¼: {output_path}")

        # --upload í”Œë˜ê·¸ ì²˜ë¦¬
        if validated_args.upload:
            print("\nğŸ“¤ YouTube ì—…ë¡œë“œ ì‹œì‘...")
            # DBì—ì„œ ìµœì‹  MergeJob ID ì¡°íšŒ
            merge_job_id = None
            description = ""
            try:
                conn = init_database()
                repo = MergeJobRepository(conn)
                job = repo.get_latest()
                if job:
                    merge_job_id = job.id
                    description = job.summary_markdown or ""
                conn.close()
            except Exception as e:
                logger.warning(f"Failed to get merge job: {e}")

            upload_to_youtube(
                file_path=output_path,
                description=description,
                merge_job_id=merge_job_id,
            )

    except FileNotFoundError as e:
        logger.error(str(e))
        sys.exit(1)
    except ValueError as e:
        logger.error(str(e))
        sys.exit(1)
    except KeyboardInterrupt:
        logger.info("\nInterrupted by user")
        sys.exit(130)
    except Exception as e:
        logger.exception(f"Unexpected error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
