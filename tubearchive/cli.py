"""CLI ì¸í„°í˜ì´ìŠ¤."""

import argparse
import json
import logging
import os
import re
import shutil
import sys
import tempfile
from dataclasses import dataclass
from pathlib import Path

from tubearchive import __version__
from tubearchive.core.detector import detect_metadata
from tubearchive.core.merger import Merger
from tubearchive.core.scanner import scan_videos
from tubearchive.core.transcoder import Transcoder
from tubearchive.database.repository import MergeJobRepository
from tubearchive.database.schema import init_database
from tubearchive.utils.progress import MultiProgressBar

logger = logging.getLogger(__name__)

# í™˜ê²½ ë³€ìˆ˜
ENV_OUTPUT_DIR = "TUBEARCHIVE_OUTPUT_DIR"
ENV_YOUTUBE_PLAYLIST = "TUBEARCHIVE_YOUTUBE_PLAYLIST"

# YYYYMMDD íŒ¨í„´ (íŒŒì¼ëª… ì‹œì‘ ë¶€ë¶„)
DATE_PATTERN = re.compile(r"^(\d{4})(\d{2})(\d{2})\s*(.*)$")


def format_youtube_title(title: str) -> str:
    """
    YouTube ì œëª© í¬ë§·íŒ….

    YYYYMMDD í˜•ì‹ì˜ ë‚ ì§œë¥¼ 'YYYYë…„ Mì›” Dì¼'ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ì˜ˆ: '20240115 ë„ì¿„ ì—¬í–‰' â†’ '2024ë…„ 1ì›” 15ì¼ ë„ì¿„ ì—¬í–‰'

    Args:
        title: ì›ë³¸ ì œëª©

    Returns:
        í¬ë§·íŒ…ëœ ì œëª©
    """
    match = DATE_PATTERN.match(title)
    if match:
        year, month, day, rest = match.groups()
        # ì•ì˜ 0 ì œê±° (01 â†’ 1)
        month_int = int(month)
        day_int = int(day)
        formatted = f"{year}ë…„ {month_int}ì›” {day_int}ì¼"
        if rest:
            formatted += f" {rest}"
        return formatted
    return title


def get_default_output_dir() -> Path | None:
    """í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê¸°ë³¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ ê°€ì ¸ì˜¤ê¸°."""
    env_dir = os.environ.get(ENV_OUTPUT_DIR)
    if env_dir:
        path = Path(env_dir)
        if path.is_dir():
            return path
        logger.warning(f"{ENV_OUTPUT_DIR}={env_dir} is not a valid directory")
    return None


def get_temp_dir() -> Path:
    """ì‹œìŠ¤í…œ ì„ì‹œ ë””ë ‰í† ë¦¬ ë‚´ tubearchive í´ë” ë°˜í™˜."""
    temp_base = Path(tempfile.gettempdir()) / "tubearchive"
    temp_base.mkdir(exist_ok=True)
    return temp_base


def check_output_disk_space(output_dir: Path, required_bytes: int) -> bool:
    """
    ì¶œë ¥ ë””ë ‰í† ë¦¬ ë””ìŠ¤í¬ ê³µê°„ í™•ì¸.

    Args:
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        required_bytes: í•„ìš”í•œ ë°”ì´íŠ¸ ìˆ˜

    Returns:
        ê³µê°„ì´ ì¶©ë¶„í•˜ë©´ True
    """
    usage = shutil.disk_usage(output_dir)
    if usage.free < required_bytes:
        logger.warning(
            f"Insufficient disk space: {usage.free / (1024**3):.1f}GB available, "
            f"{required_bytes / (1024**3):.1f}GB required"
        )
        return False
    return True


@dataclass
class ValidatedArgs:
    """ê²€ì¦ëœ CLI ì¸ì."""

    targets: list[Path]
    output: Path | None
    output_dir: Path | None
    no_resume: bool
    keep_temp: bool
    dry_run: bool
    upload: bool = False


def create_parser() -> argparse.ArgumentParser:
    """
    CLI íŒŒì„œ ìƒì„±.

    Returns:
        argparse.ArgumentParser ì¸ìŠ¤í„´ìŠ¤
    """
    parser = argparse.ArgumentParser(
        prog="tubearchive",
        description=f"ë‹¤ì–‘í•œ ê¸°ê¸°ì˜ 4K ì˜ìƒì„ í‘œì¤€í™”í•˜ì—¬ ë³‘í•©í•©ë‹ˆë‹¤. (v{__version__})",
        epilog=(
            "ì˜ˆì‹œ:\n"
            "  tubearchive video1.mp4 video2.mov -o merged.mp4  # ë³‘í•©\n"
            "  tubearchive ~/Videos/ --upload                   # ë³‘í•© í›„ ì—…ë¡œë“œ\n"
            "  tubearchive --upload-only merged.mp4             # ì—…ë¡œë“œë§Œ"
        ),
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )

    parser.add_argument(
        "-V", "--version",
        action="version",
        version=f"%(prog)s {__version__}",
    )

    parser.add_argument(
        "targets",
        nargs="*",
        default=[],
        help="ì˜ìƒ íŒŒì¼ ë˜ëŠ” ë””ë ‰í† ë¦¬ (ê¸°ë³¸: í˜„ì¬ ë””ë ‰í† ë¦¬)",
    )

    parser.add_argument(
        "-o", "--output",
        type=str,
        default=None,
        help="ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸: merged_output.mp4)",
    )

    parser.add_argument(
        "--no-resume",
        action="store_true",
        help="Resume ê¸°ëŠ¥ ë¹„í™œì„±í™”",
    )

    parser.add_argument(
        "--keep-temp",
        action="store_true",
        help="ì„ì‹œ íŒŒì¼ ë³´ì¡´ (ë””ë²„ê¹…ìš©)",
    )

    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ì‹¤í–‰ ê³„íšë§Œ ì¶œë ¥ (ì‹¤ì œ ì‹¤í–‰ ì•ˆ í•¨)",
    )

    parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥",
    )

    parser.add_argument(
        "--output-dir",
        type=str,
        default=None,
        help=f"ì¶œë ¥ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬ (í™˜ê²½ë³€ìˆ˜: {ENV_OUTPUT_DIR})",
    )

    # YouTube ì—…ë¡œë“œ ì˜µì…˜
    parser.add_argument(
        "--upload",
        action="store_true",
        help="ë³‘í•© ì™„ë£Œ í›„ YouTubeì— ì—…ë¡œë“œ",
    )

    parser.add_argument(
        "--upload-only",
        type=str,
        metavar="FILE",
        default=None,
        help="ì§€ì •ëœ íŒŒì¼ì„ YouTubeì— ì—…ë¡œë“œ (ë³‘í•© ì—†ì´)",
    )

    parser.add_argument(
        "--upload-title",
        type=str,
        default=None,
        help="YouTube ì—…ë¡œë“œ ì‹œ ì˜ìƒ ì œëª© (ê¸°ë³¸: íŒŒì¼ëª…)",
    )

    parser.add_argument(
        "--upload-privacy",
        type=str,
        default="unlisted",
        choices=["public", "unlisted", "private"],
        help="YouTube ê³µê°œ ì„¤ì • (ê¸°ë³¸: unlisted)",
    )

    parser.add_argument(
        "--playlist",
        type=str,
        action="append",
        default=None,
        metavar="ID",
        help=(
            "ì—…ë¡œë“œ í›„ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ "
            f"(í™˜ê²½ë³€ìˆ˜: {ENV_YOUTUBE_PLAYLIST}, ì‰¼í‘œë¡œ êµ¬ë¶„)"
        ),
    )

    parser.add_argument(
        "--setup-youtube",
        action="store_true",
        help="YouTube ì¸ì¦ ìƒíƒœ í™•ì¸ ë° ì„¤ì • ê°€ì´ë“œ ì¶œë ¥",
    )

    parser.add_argument(
        "--youtube-auth",
        action="store_true",
        help="YouTube ë¸Œë¼ìš°ì € ì¸ì¦ ì‹¤í–‰",
    )

    parser.add_argument(
        "--list-playlists",
        action="store_true",
        help="ë‚´ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ëª©ë¡ ì¡°íšŒ",
    )

    return parser


def validate_args(args: argparse.Namespace) -> ValidatedArgs:
    """
    CLI ì¸ì ê²€ì¦.

    Args:
        args: íŒŒì‹±ëœ ì¸ì

    Returns:
        ê²€ì¦ëœ ì¸ì

    Raises:
        FileNotFoundError: íŒŒì¼/ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°
    """
    # targets ê²€ì¦
    targets: list[Path] = []
    if not args.targets:
        targets = [Path.cwd()]
    else:
        for target in args.targets:
            path = Path(target)
            if not path.exists():
                raise FileNotFoundError(f"Target not found: {target}")
            targets.append(path)

    # output ê²€ì¦
    output: Path | None = None
    if args.output:
        output = Path(args.output)
        if not output.parent.exists():
            raise FileNotFoundError(f"Output directory not found: {output.parent}")

    # output_dir ê²€ì¦ (CLI ì¸ì > í™˜ê²½ ë³€ìˆ˜ > None)
    output_dir: Path | None = None
    if args.output_dir:
        output_dir = Path(args.output_dir)
        if not output_dir.is_dir():
            raise FileNotFoundError(f"Output directory not found: {args.output_dir}")
    else:
        output_dir = get_default_output_dir()

    # upload í”Œë˜ê·¸ í™•ì¸
    upload = getattr(args, "upload", False)

    return ValidatedArgs(
        targets=targets,
        output=output,
        output_dir=output_dir,
        no_resume=args.no_resume,
        keep_temp=args.keep_temp,
        dry_run=args.dry_run,
        upload=upload,
    )


def setup_logging(verbose: bool = False) -> None:
    """
    ë¡œê¹… ì„¤ì •.

    Args:
        verbose: ìƒì„¸ ë¡œê·¸ ì—¬ë¶€
    """
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
    )


def get_output_filename(targets: list[Path]) -> str:
    """
    ì…ë ¥ íƒ€ê²Ÿì—ì„œ ì¶œë ¥ íŒŒì¼ëª… ìƒì„±.

    ë””ë ‰í† ë¦¬ëª… ë˜ëŠ” ì²« ë²ˆì§¸ íŒŒì¼ì˜ ë¶€ëª¨ ë””ë ‰í† ë¦¬ëª…ì„ ì‚¬ìš©.

    Args:
        targets: ì…ë ¥ íƒ€ê²Ÿ ëª©ë¡

    Returns:
        ì¶œë ¥ íŒŒì¼ëª… (í™•ì¥ì í¬í•¨)
    """
    if not targets:
        return "output.mp4"

    first_target = targets[0]
    if first_target.is_dir():
        # ë””ë ‰í† ë¦¬ë©´ ë””ë ‰í† ë¦¬ëª… ì‚¬ìš©
        name = first_target.name
    else:
        # íŒŒì¼ì´ë©´ ë¶€ëª¨ ë””ë ‰í† ë¦¬ëª… ì‚¬ìš©
        name = first_target.parent.name

    # ë¹ˆ ì´ë¦„ì´ê±°ë‚˜ í˜„ì¬ ë””ë ‰í† ë¦¬ë©´ ê¸°ë³¸ê°’
    if not name or name == ".":
        name = "output"

    return f"{name}.mp4"


def run_pipeline(validated_args: ValidatedArgs) -> Path:
    """
    ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰.

    Args:
        validated_args: ê²€ì¦ëœ ì¸ì

    Returns:
        ìµœì¢… ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    """
    # 1. íŒŒì¼ ìŠ¤ìº”
    logger.info("Scanning video files...")
    video_files = scan_videos(validated_args.targets)

    if not video_files:
        logger.error("No video files found")
        raise ValueError("No video files found")

    logger.info(f"Found {len(video_files)} video files")
    for vf in video_files:
        logger.info(f"  - {vf.path.name}")

    # 2. íŠ¸ëœìŠ¤ì½”ë”© (ì„ì‹œ íŒŒì¼ì€ /tmpì— ì €ì¥)
    temp_dir = get_temp_dir()
    logger.info(f"Using temp directory: {temp_dir}")
    logger.info("Starting transcoding...")
    transcoded_paths: list[Path] = []
    # (íŒŒì¼ëª…, duration, device_model, creation_time_str)
    video_clips: list[tuple[str, float, str | None, str | None]] = []
    progress = MultiProgressBar(total_files=len(video_files))

    with Transcoder(temp_dir=temp_dir) as transcoder:
        for vf in video_files:
            progress.start_file(vf.path.name)

            def on_progress(percent: int) -> None:
                progress.update_file_progress(percent)

            output_path = transcoder.transcode_video(vf)
            transcoded_paths.append(output_path)

            # ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ (Summaryìš©)
            try:
                metadata = detect_metadata(vf.path)
                creation_time_str = vf.creation_time.strftime("%H:%M:%S")
                video_clips.append((
                    vf.path.name,
                    metadata.duration_seconds,
                    metadata.device_model,
                    creation_time_str,
                ))
            except Exception as e:
                logger.warning(f"Failed to get metadata for {vf.path}: {e}")
                video_clips.append((vf.path.name, 0.0, None, None))

            progress.finish_file()

    # 3. ë³‘í•©
    logger.info("Merging videos...")

    # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ê²°ì •
    if validated_args.output:
        output_path = validated_args.output
    else:
        output_filename = get_output_filename(validated_args.targets)
        output_dir = validated_args.output_dir or Path.cwd()
        output_path = output_dir / output_filename

    merger = Merger(temp_dir=temp_dir)
    final_path = merger.merge(transcoded_paths, output_path)

    logger.info(f"Final output: {final_path}")

    # 4. DBì— íƒ€ì„ë¼ì¸ ì •ë³´ ì €ì¥ ë° Summary ìƒì„±
    summary_markdown = save_merge_job_to_db(
        final_path, video_clips, validated_args.targets
    )

    # 5. ì„ì‹œ íŒŒì¼ ë° í´ë” ì •ë¦¬
    if not validated_args.keep_temp:
        logger.info("Cleaning up temporary files...")
        for temp_path in transcoded_paths:
            if temp_path.exists() and temp_path != final_path:
                temp_path.unlink()
                logger.debug(f"  Removed: {temp_path}")

        # ì„ì‹œ í´ë” ì‚­ì œ (ë¹„ì–´ìˆê±°ë‚˜ concat íŒŒì¼ë§Œ ë‚¨ì€ ê²½ìš°)
        if temp_dir.exists():
            try:
                shutil.rmtree(temp_dir)
                logger.info(f"Removed temp directory: {temp_dir}")
            except OSError as e:
                logger.warning(f"Failed to remove temp directory: {e}")

    # 6. Summary ì¶œë ¥ (ë³µì‚¬í•´ì„œ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥)
    if summary_markdown:
        print("\n" + "=" * 60)
        print("ğŸ“‹ SUMMARY (Copy & Paste)")
        print("=" * 60)
        print(summary_markdown)
        print("=" * 60 + "\n")

    return final_path


def save_merge_job_to_db(
    output_path: Path,
    video_clips: list[tuple[str, float, str | None, str | None]],
    targets: list[Path],
) -> str | None:
    """
    ë³‘í•© ì‘ì—… ì •ë³´ë¥¼ DBì— ì €ì¥ (íƒ€ì„ë¼ì¸ ë° Summary í¬í•¨).

    Args:
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        video_clips: (íŒŒì¼ëª…, ì¬ìƒì‹œê°„, ê¸°ì¢…, ì´¬ì˜ì‹œê°„) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        targets: ì…ë ¥ íƒ€ê²Ÿ ëª©ë¡ (ì œëª© ì¶”ì¶œìš©)

    Returns:
        ìƒì„±ëœ Summary ë§ˆí¬ë‹¤ìš´ (ì‹¤íŒ¨ ì‹œ None)
    """
    from tubearchive.utils.summary_generator import (
        generate_clip_summary,
        generate_youtube_description,
    )

    try:
        conn = init_database()
        repo = MergeJobRepository(conn)

        # íƒ€ì„ë¼ì¸ ì •ë³´ ìƒì„± (ê° í´ë¦½ì˜ ë©”íƒ€ë°ì´í„° í¬í•¨)
        timeline: list[dict[str, str | float | None]] = []
        current_time = 0.0
        for name, duration, device, shot_time in video_clips:
            timeline.append({
                "name": name,
                "duration": duration,
                "start": current_time,
                "end": current_time + duration,
                "device": device,
                "shot_time": shot_time,
            })
            current_time += duration

        clips_json = json.dumps(timeline, ensure_ascii=False)

        # ì œëª©: ë””ë ‰í† ë¦¬ëª…
        title = None
        if targets:
            first_target = targets[0]
            if first_target.is_dir():
                title = first_target.name
            else:
                title = first_target.parent.name
            if not title or title == ".":
                title = output_path.stem

        # ë‚ ì§œ: ì˜¤ëŠ˜
        from datetime import date
        today = date.today().isoformat()

        # ì´ ì¬ìƒì‹œê°„ ë° íŒŒì¼ í¬ê¸°
        total_duration = sum(d for _, d, _, _ in video_clips)
        total_size = output_path.stat().st_size if output_path.exists() else 0

        # ì½˜ì†” ì¶œë ¥ìš© ìš”ì•½ (ë§ˆí¬ë‹¤ìš´ í˜•ì‹)
        console_summary = generate_clip_summary(video_clips)

        # YouTube ì„¤ëª…ìš© (íƒ€ì„ìŠ¤íƒ¬í”„ + ì´¬ì˜ê¸°ê¸°)
        youtube_description = generate_youtube_description(video_clips)

        repo.create(
            output_path=output_path,
            video_ids=[],
            title=title,
            date=today,
            total_duration_seconds=total_duration,
            total_size_bytes=total_size,
            clips_info_json=clips_json,
            summary_markdown=youtube_description,  # YouTube ì„¤ëª…ìš©ìœ¼ë¡œ ì €ì¥
        )
        conn.close()
        logger.debug("Merge job saved to database with summary")
        return console_summary  # ì½˜ì†”ì—ëŠ” ìƒì„¸ ìš”ì•½ ì¶œë ¥

    except Exception as e:
        logger.warning(f"Failed to save merge job to DB: {e}")
        return None


def upload_to_youtube(
    file_path: Path,
    title: str | None = None,
    description: str = "",
    privacy: str = "unlisted",
    merge_job_id: int | None = None,
    playlist_ids: list[str] | None = None,
) -> None:
    """
    ì˜ìƒì„ YouTubeì— ì—…ë¡œë“œ.

    Args:
        file_path: ì—…ë¡œë“œí•  ì˜ìƒ íŒŒì¼ ê²½ë¡œ
        title: ì˜ìƒ ì œëª© (Noneì´ë©´ íŒŒì¼ëª… ì‚¬ìš©)
        description: ì˜ìƒ ì„¤ëª…
        privacy: ê³µê°œ ì„¤ì • (public, unlisted, private)
        merge_job_id: DBì— ì €ì¥í•  MergeJob ID
        playlist_ids: ì¶”ê°€í•  í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ì¶”ê°€ ì•ˆ í•¨)
    """
    from tubearchive.youtube.auth import YouTubeAuthError, get_authenticated_service
    from tubearchive.youtube.playlist import PlaylistError, add_to_playlist
    from tubearchive.youtube.uploader import YouTubeUploader, YouTubeUploadError

    if not file_path.exists():
        raise FileNotFoundError(f"Video file not found: {file_path}")

    # ì œëª© ê²°ì •: ì§€ì •ê°’ > íŒŒì¼ëª…(í™•ì¥ì ì œì™¸)
    # YYYYMMDD í˜•ì‹ì„ 'YYYYë…„ Mì›” Dì¼'ë¡œ ë³€í™˜
    raw_title = title or file_path.stem
    video_title = format_youtube_title(raw_title)

    logger.info(f"Uploading to YouTube: {file_path}")
    logger.info(f"  Title: {video_title}")
    logger.info(f"  Privacy: {privacy}")

    # ì¸ì¦ ìƒíƒœ í™•ì¸
    from tubearchive.youtube.auth import check_auth_status

    status = check_auth_status()

    if not status.has_client_secrets:
        print("\nâŒ YouTube ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        print(f"\n{status.get_setup_guide()}")
        print("\nì„¤ì • ì™„ë£Œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        raise YouTubeAuthError("client_secrets.json not found")

    if not status.has_valid_token:
        print("\nğŸ” YouTube ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        print("   ë¸Œë¼ìš°ì €ì—ì„œ Google ê³„ì • ì¸ì¦ì„ ì§„í–‰í•©ë‹ˆë‹¤...\n")

    try:
        # ì¸ì¦ (í† í° ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ë¸Œë¼ìš°ì € ì—´ë¦¼)
        service = get_authenticated_service()

        # ì—…ë¡œë“œ
        uploader = YouTubeUploader(service)

        # í”„ë¡œê·¸ë ˆìŠ¤ ë°” ì„¤ì •
        file_size_mb = file_path.stat().st_size / (1024 * 1024)
        bar_width = 30

        def on_progress(percent: int) -> None:
            filled = int(bar_width * percent / 100)
            bar = "â–ˆ" * filled + "â–‘" * (bar_width - filled)
            msg = f"\rğŸ“¤ ì—…ë¡œë“œ: [{bar}] {percent:3d}% ({file_size_mb:.1f}MB)"
            print(msg, end="", flush=True)
            if percent >= 100:
                print()  # ì™„ë£Œ ì‹œ ì¤„ë°”ê¿ˆ

        result = uploader.upload(
            file_path=file_path,
            title=video_title,
            description=description,
            privacy=privacy,
            on_progress=on_progress,
        )

        print("\nâœ… YouTube ì—…ë¡œë“œ ì™„ë£Œ!")
        print(f"ğŸ¬ URL: {result.url}")

        # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        if playlist_ids:
            for pid in playlist_ids:
                try:
                    add_to_playlist(service, pid, result.video_id)
                    print(f"ğŸ“‹ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ë¨: {pid}")
                except PlaylistError as e:
                    logger.warning(f"Failed to add to playlist {pid}: {e}")
                    print(f"âš ï¸ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì¶”ê°€ ì‹¤íŒ¨ ({pid}): {e}")

        # DBì— YouTube ID ì €ì¥
        if merge_job_id is not None:
            try:
                conn = init_database()
                repo = MergeJobRepository(conn)
                repo.update_youtube_id(merge_job_id, result.video_id)
                conn.close()
                logger.debug(f"YouTube ID {result.video_id} saved to merge job {merge_job_id}")
            except Exception as e:
                logger.warning(f"Failed to save YouTube ID to DB: {e}")

    except YouTubeAuthError as e:
        logger.error(f"YouTube authentication failed: {e}")
        print(f"\nâŒ YouTube ì¸ì¦ ì‹¤íŒ¨: {e}")
        print("\nì„¤ì • ê°€ì´ë“œ: tubearchive --setup-youtube")
        raise
    except YouTubeUploadError as e:
        logger.error(f"YouTube upload failed: {e}")
        print(f"\nâŒ YouTube ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise


def cmd_setup_youtube() -> None:
    """
    --setup-youtube ì˜µì…˜ ì²˜ë¦¬.

    YouTube ì¸ì¦ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ì„¤ì • ê°€ì´ë“œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    from tubearchive.youtube.auth import check_auth_status

    print("\nğŸ¬ YouTube ì—…ë¡œë“œ ì„¤ì • ìƒíƒœ\n")
    print("=" * 50)

    status = check_auth_status()
    print(status.get_setup_guide())

    print("=" * 50)

    # ë¸Œë¼ìš°ì € ì¸ì¦ì´ í•„ìš”í•˜ë©´ ë°”ë¡œ ì‹¤í–‰ ì œì•ˆ
    if status.needs_browser_auth:
        print("\nğŸ’¡ ì§€ê¸ˆ ë°”ë¡œ ì¸ì¦í•˜ë ¤ë©´:")
        print("   tubearchive --youtube-auth")
        print("   (ë¸Œë¼ìš°ì €ê°€ ì—´ë¦¬ë©° Google ê³„ì • ì¸ì¦ì´ ì§„í–‰ë©ë‹ˆë‹¤)")


def cmd_youtube_auth() -> None:
    """
    --youtube-auth ì˜µì…˜ ì²˜ë¦¬.

    ë¸Œë¼ìš°ì €ë¥¼ ì—´ì–´ YouTube OAuth ì¸ì¦ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    from tubearchive.youtube.auth import (
        YouTubeAuthError,
        check_auth_status,
        get_client_secrets_path,
        get_token_path,
        run_auth_flow,
        save_credentials,
    )

    print("\nğŸ” YouTube ì¸ì¦ ì‹œì‘\n")

    # ë¨¼ì € ìƒíƒœ í™•ì¸
    status = check_auth_status()

    if status.has_valid_token:
        print("âœ… ì´ë¯¸ ì¸ì¦ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")
        print(f"   í† í° ìœ„ì¹˜: {status.token_path}")
        return

    if not status.has_client_secrets:
        print("âŒ client_secrets.jsonì´ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   í•„ìš”í•œ ìœ„ì¹˜: {status.client_secrets_path}")
        print("\nì„¤ì • ê°€ì´ë“œë¥¼ ë³´ë ¤ë©´: tubearchive --setup-youtube")
        raise YouTubeAuthError("client_secrets.json not found")

    # ë¸Œë¼ìš°ì € ì¸ì¦ ì‹¤í–‰
    print("ğŸŒ ë¸Œë¼ìš°ì €ì—ì„œ Google ê³„ì • ì¸ì¦ì„ ì§„í–‰í•©ë‹ˆë‹¤...")
    print("   (ë¸Œë¼ìš°ì €ê°€ ìë™ìœ¼ë¡œ ì—´ë¦½ë‹ˆë‹¤)\n")

    try:
        secrets_path = get_client_secrets_path()
        token_path = get_token_path()

        credentials = run_auth_flow(secrets_path)
        save_credentials(credentials, token_path)

        print("\nâœ… ì¸ì¦ ì™„ë£Œ!")
        print(f"   í† í° ì €ì¥ë¨: {token_path}")
        print("\nì´ì œ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
        print("   tubearchive --upload ~/Videos/")
        print("   tubearchive --upload-only video.mp4")

    except Exception as e:
        logger.error(f"YouTube authentication failed: {e}")
        print(f"\nâŒ ì¸ì¦ ì‹¤íŒ¨: {e}")
        raise


def cmd_list_playlists() -> None:
    """
    --list-playlists ì˜µì…˜ ì²˜ë¦¬.

    ë‚´ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ëª©ë¡ì„ ì¡°íšŒí•˜ì—¬ IDì™€ í•¨ê»˜ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    from tubearchive.youtube.auth import get_authenticated_service
    from tubearchive.youtube.playlist import list_playlists

    print("\nğŸ“‹ ë‚´ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ëª©ë¡\n")

    try:
        service = get_authenticated_service()
        playlists = list_playlists(service)

        if not playlists:
            print("í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"{'ë²ˆí˜¸':<4} {'ì œëª©':<40} {'ì˜ìƒìˆ˜':<8} ID")
        print("-" * 80)
        for i, pl in enumerate(playlists, 1):
            print(f"{i:<4} {pl.title:<40} {pl.item_count:<8} {pl.id}")

        print("-" * 80)
        print("\nğŸ’¡ í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì˜ˆì‹œ:")
        print(f"   export {ENV_YOUTUBE_PLAYLIST}={playlists[0].id}")
        if len(playlists) > 1:
            ids = ",".join(pl.id for pl in playlists[:2])
            print(f"   export {ENV_YOUTUBE_PLAYLIST}={ids}  # ì—¬ëŸ¬ ê°œ")

    except Exception as e:
        logger.error(f"Failed to list playlists: {e}")
        print(f"\nâŒ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")

        # ìŠ¤ì½”í”„ ë¶€ì¡± ì—ëŸ¬ ì²˜ë¦¬
        if "insufficient" in str(e).lower() or "scope" in str(e).lower():
            from tubearchive.youtube.auth import get_token_path

            token_path = get_token_path()
            print("\nğŸ’¡ ê¶Œí•œì´ ë¶€ì¡±í•©ë‹ˆë‹¤. í† í°ì„ ì‚­ì œí•˜ê³  ì¬ì¸ì¦í•˜ì„¸ìš”:")
            print(f"   rm {token_path}")
            print("   tubearchive --youtube-auth")
        raise


def resolve_playlist_ids(playlist_args: list[str] | None) -> list[str]:
    """
    í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì¸ì ì²˜ë¦¬.

    ìš°ì„ ìˆœìœ„:
    1. --playlist ì˜µì…˜ì´ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •ë¨ â†’ í•´ë‹¹ ê°’ ì‚¬ìš©
    2. --playlist ì˜µì…˜ ì—†ìŒ + í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ë¨ â†’ í™˜ê²½ ë³€ìˆ˜ ê°’ ì‚¬ìš©
    3. ë‘˜ ë‹¤ ì—†ìŒ â†’ ë¹ˆ ë¦¬ìŠ¤íŠ¸ (í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì¶”ê°€ ì•ˆ í•¨)

    Args:
        playlist_args: --playlist ì¸ì ê°’ ë¦¬ìŠ¤íŠ¸
            - None: í™˜ê²½ ë³€ìˆ˜ í™•ì¸
            - ë¹ˆ ë¬¸ìì—´ í¬í•¨: ëª©ë¡ì—ì„œ ì„ íƒ
            - ê¸°íƒ€: í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ IDë¡œ ì‚¬ìš©

    Returns:
        í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID ë¦¬ìŠ¤íŠ¸ (ì‚¬ìš© ì•ˆ í•¨ ë˜ëŠ” ì·¨ì†Œ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸)
    """
    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê¸°ë³¸ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ í™•ì¸
    if playlist_args is None:
        env_playlist = os.environ.get(ENV_YOUTUBE_PLAYLIST)
        if env_playlist:
            ids = [pid.strip() for pid in env_playlist.split(",") if pid.strip()]
            if ids:
                logger.info(f"Using playlists from env: {ids}")
                return ids
        return []

    # ë¹ˆ ë¬¸ìì—´ì´ ìˆìœ¼ë©´ ì„ íƒ ëª¨ë“œ
    needs_selection = any(arg == "" for arg in playlist_args)
    direct_ids = [arg for arg in playlist_args if arg and arg != ""]

    if needs_selection:
        # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ëª©ë¡ì—ì„œ ì„ íƒ
        from tubearchive.youtube.auth import get_authenticated_service
        from tubearchive.youtube.playlist import list_playlists, select_playlist_interactive

        print("\nğŸ“‹ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        service = get_authenticated_service()
        playlists = list_playlists(service)

        selected = select_playlist_interactive(playlists)
        if selected:
            for pl in selected:
                print(f"   ì„ íƒë¨: {pl.title}")
            direct_ids.extend([pl.id for pl in selected])

    return direct_ids


def cmd_upload_only(args: argparse.Namespace) -> None:
    """
    --upload-only ì˜µì…˜ ì²˜ë¦¬.

    Args:
        args: íŒŒì‹±ëœ ì¸ì
    """
    file_path = Path(args.upload_only)

    if not file_path.exists():
        logger.error(f"File not found: {file_path}")
        sys.exit(1)

    # DBì—ì„œ MergeJob ì¡°íšŒ (ê²½ë¡œë¡œ ì°¾ê¸°)
    merge_job_id = None
    description = ""

    try:
        conn = init_database()

        # ìµœì‹  MergeJobì—ì„œ ì¼ì¹˜í•˜ëŠ” ê²½ë¡œ ì°¾ê¸°
        cursor = conn.execute(
            """SELECT id, summary_markdown FROM merge_jobs
            WHERE output_path = ? ORDER BY created_at DESC LIMIT 1""",
            (str(file_path),),
        )
        row = cursor.fetchone()
        if row:
            merge_job_id = row["id"]
            # descriptionì´ ë¹„ì–´ìˆìœ¼ë©´ summary_markdown ì‚¬ìš©
            if row["summary_markdown"]:
                description = row["summary_markdown"]
                logger.info("Using summary from database as description")

        conn.close()
    except Exception as e:
        logger.warning(f"Failed to load merge job from DB: {e}")

    # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
    playlist_ids = resolve_playlist_ids(args.playlist)

    # ì—…ë¡œë“œ ì‹¤í–‰
    upload_to_youtube(
        file_path=file_path,
        title=args.upload_title,
        description=description,
        privacy=args.upload_privacy,
        merge_job_id=merge_job_id,
        playlist_ids=playlist_ids,
    )


def main() -> None:
    """CLI ì§„ì…ì ."""
    parser = create_parser()
    args = parser.parse_args()

    setup_logging(args.verbose)

    try:
        # --setup-youtube ì˜µì…˜ ì²˜ë¦¬ (ì„¤ì • ê°€ì´ë“œ)
        if args.setup_youtube:
            cmd_setup_youtube()
            return

        # --youtube-auth ì˜µì…˜ ì²˜ë¦¬ (ë¸Œë¼ìš°ì € ì¸ì¦)
        if args.youtube_auth:
            cmd_youtube_auth()
            return

        # --list-playlists ì˜µì…˜ ì²˜ë¦¬ (í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ëª©ë¡)
        if args.list_playlists:
            cmd_list_playlists()
            return

        # --upload-only ì˜µì…˜ ì²˜ë¦¬ (ì—…ë¡œë“œë§Œ)
        if args.upload_only:
            cmd_upload_only(args)
            return

        validated_args = validate_args(args)

        if validated_args.dry_run:
            # Dry run: ì‹¤í–‰ ê³„íšë§Œ ì¶œë ¥
            logger.info("Dry run mode - showing execution plan only")

            video_files = scan_videos(validated_args.targets)
            temp_dir = get_temp_dir()

            # ì¶œë ¥ ê²½ë¡œ ê³„ì‚°
            if validated_args.output:
                output_str = str(validated_args.output)
            else:
                output_filename = get_output_filename(validated_args.targets)
                output_dir = validated_args.output_dir or Path.cwd()
                output_str = str(output_dir / output_filename)

            print("\n=== Dry Run Execution Plan ===")
            print(f"Input targets: {[str(t) for t in validated_args.targets]}")
            print(f"Video files found: {len(video_files)}")
            for vf in video_files:
                print(f"  - {vf.path}")
            print(f"Output: {output_str}")
            print(f"Temp dir: {temp_dir}")
            print(f"Resume enabled: {not validated_args.no_resume}")
            print(f"Keep temp files: {validated_args.keep_temp}")
            print("=" * 30)
            return

        output_path = run_pipeline(validated_args)
        print("\nâœ… ì™„ë£Œ!")
        print(f"ğŸ“¹ ì¶œë ¥ íŒŒì¼: {output_path}")

        # --upload í”Œë˜ê·¸ ì²˜ë¦¬
        if validated_args.upload:
            print("\nğŸ“¤ YouTube ì—…ë¡œë“œ ì‹œì‘...")
            # DBì—ì„œ ìµœì‹  MergeJob ID ì¡°íšŒ
            merge_job_id = None
            description = ""
            try:
                conn = init_database()
                repo = MergeJobRepository(conn)
                job = repo.get_latest()
                if job:
                    merge_job_id = job.id
                    description = job.summary_markdown or ""
                conn.close()
            except Exception as e:
                logger.warning(f"Failed to get merge job: {e}")

            # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
            playlist_ids = resolve_playlist_ids(args.playlist)

            upload_to_youtube(
                file_path=output_path,
                description=description,
                merge_job_id=merge_job_id,
                playlist_ids=playlist_ids,
            )

    except FileNotFoundError as e:
        logger.error(str(e))
        sys.exit(1)
    except ValueError as e:
        logger.error(str(e))
        sys.exit(1)
    except KeyboardInterrupt:
        logger.info("\nInterrupted by user")
        sys.exit(130)
    except Exception as e:
        logger.exception(f"Unexpected error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
