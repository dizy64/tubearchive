"""CLI ì¸í„°í˜ì´ìŠ¤."""

import argparse
import json
import logging
import os
import re
import shutil
import sys
import tempfile
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from datetime import date
from pathlib import Path
from threading import Lock

try:
    import termios

    HAS_TERMIOS = True
except ImportError:
    HAS_TERMIOS = False

from tubearchive import __version__
from tubearchive.core.detector import detect_metadata
from tubearchive.core.merger import Merger
from tubearchive.core.scanner import scan_videos
from tubearchive.core.transcoder import Transcoder
from tubearchive.database.repository import MergeJobRepository
from tubearchive.database.schema import init_database
from tubearchive.models.video import VideoFile
from tubearchive.utils.progress import MultiProgressBar, ProgressInfo
from tubearchive.utils.summary_generator import generate_single_file_description

logger = logging.getLogger(__name__)


def safe_input(prompt: str) -> str:
    """
    í„°ë¯¸ë„ ìƒíƒœë¥¼ ë³µì›í•˜ê³  ì•ˆì „í•˜ê²Œ ì…ë ¥ ë°›ê¸°.

    Args:
        prompt: ì…ë ¥ í”„ë¡¬í”„íŠ¸

    Returns:
        ì‚¬ìš©ì ì…ë ¥ (strip ì ìš©)
    """
    # í„°ë¯¸ë„ ìƒíƒœ ë³µì› ì‹œë„
    if HAS_TERMIOS and sys.stdin.isatty():
        try:
            # í˜„ì¬ í„°ë¯¸ë„ ì„¤ì • ì €ì¥
            fd = sys.stdin.fileno()
            old_settings = termios.tcgetattr(fd)
            # cooked ëª¨ë“œë¡œ ë³µì› (ì¼ë°˜ ë¼ì¸ ì…ë ¥ ëª¨ë“œ)
            termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)
        except (termios.error, OSError):
            pass

    sys.stdout.write(prompt)
    sys.stdout.flush()

    try:
        line = sys.stdin.readline()
        return line.strip().replace("\r", "")
    except (EOFError, KeyboardInterrupt):
        return ""


# í™˜ê²½ ë³€ìˆ˜
ENV_OUTPUT_DIR = "TUBEARCHIVE_OUTPUT_DIR"
ENV_YOUTUBE_PLAYLIST = "TUBEARCHIVE_YOUTUBE_PLAYLIST"
ENV_PARALLEL = "TUBEARCHIVE_PARALLEL"

# YYYYMMDD íŒ¨í„´ (íŒŒì¼ëª… ì‹œì‘ ë¶€ë¶„)
DATE_PATTERN = re.compile(r"^(\d{4})(\d{2})(\d{2})\s*(.*)$")


def format_youtube_title(title: str) -> str:
    """
    YouTube ì œëª© í¬ë§·íŒ….

    YYYYMMDD í˜•ì‹ì˜ ë‚ ì§œë¥¼ 'YYYYë…„ Mì›” Dì¼'ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ì˜ˆ: '20240115 ë„ì¿„ ì—¬í–‰' â†’ '2024ë…„ 1ì›” 15ì¼ ë„ì¿„ ì—¬í–‰'

    Args:
        title: ì›ë³¸ ì œëª©

    Returns:
        í¬ë§·íŒ…ëœ ì œëª©
    """
    match = DATE_PATTERN.match(title)
    if match:
        year, month, day, rest = match.groups()
        # ì•ì˜ 0 ì œê±° (01 â†’ 1)
        month_int = int(month)
        day_int = int(day)
        formatted = f"{year}ë…„ {month_int}ì›” {day_int}ì¼"
        if rest:
            formatted += f" {rest}"
        return formatted
    return title


def get_default_output_dir() -> Path | None:
    """í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê¸°ë³¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ ê°€ì ¸ì˜¤ê¸°."""
    env_dir = os.environ.get(ENV_OUTPUT_DIR)
    if env_dir:
        path = Path(env_dir)
        if path.is_dir():
            return path
        logger.warning(f"{ENV_OUTPUT_DIR}={env_dir} is not a valid directory")
    return None


def get_temp_dir() -> Path:
    """ì‹œìŠ¤í…œ ì„ì‹œ ë””ë ‰í† ë¦¬ ë‚´ tubearchive í´ë” ë°˜í™˜."""
    temp_base = Path(tempfile.gettempdir()) / "tubearchive"
    temp_base.mkdir(exist_ok=True)
    return temp_base


def check_output_disk_space(output_dir: Path, required_bytes: int) -> bool:
    """
    ì¶œë ¥ ë””ë ‰í† ë¦¬ ë””ìŠ¤í¬ ê³µê°„ í™•ì¸.

    Args:
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        required_bytes: í•„ìš”í•œ ë°”ì´íŠ¸ ìˆ˜

    Returns:
        ê³µê°„ì´ ì¶©ë¶„í•˜ë©´ True
    """
    usage = shutil.disk_usage(output_dir)
    if usage.free < required_bytes:
        logger.warning(
            f"Insufficient disk space: {usage.free / (1024**3):.1f}GB available, "
            f"{required_bytes / (1024**3):.1f}GB required"
        )
        return False
    return True


def get_default_parallel() -> int:
    """í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê¸°ë³¸ ë³‘ë ¬ ì²˜ë¦¬ ìˆ˜ ê°€ì ¸ì˜¤ê¸°."""
    env_parallel = os.environ.get(ENV_PARALLEL)
    if env_parallel:
        try:
            val = int(env_parallel)
            if val >= 1:
                return val
            logger.warning(f"{ENV_PARALLEL}={env_parallel} must be >= 1, using 1")
        except ValueError:
            logger.warning(f"{ENV_PARALLEL}={env_parallel} is not a valid number")
    return 1  # ê¸°ë³¸ê°’: ìˆœì°¨ ì²˜ë¦¬


@dataclass
class ValidatedArgs:
    """ê²€ì¦ëœ CLI ì¸ì."""

    targets: list[Path]
    output: Path | None
    output_dir: Path | None
    no_resume: bool
    keep_temp: bool
    dry_run: bool
    upload: bool = False
    parallel: int = 1


def create_parser() -> argparse.ArgumentParser:
    """
    CLI íŒŒì„œ ìƒì„±.

    Returns:
        argparse.ArgumentParser ì¸ìŠ¤í„´ìŠ¤
    """
    parser = argparse.ArgumentParser(
        prog="tubearchive",
        description=f"ë‹¤ì–‘í•œ ê¸°ê¸°ì˜ 4K ì˜ìƒì„ í‘œì¤€í™”í•˜ì—¬ ë³‘í•©í•©ë‹ˆë‹¤. (v{__version__})",
        epilog=(
            "ì˜ˆì‹œ:\n"
            "  tubearchive video1.mp4 video2.mov -o merged.mp4  # ë³‘í•©\n"
            "  tubearchive ~/Videos/ --upload                   # ë³‘í•© í›„ ì—…ë¡œë“œ\n"
            "  tubearchive --upload-only merged.mp4             # ì—…ë¡œë“œë§Œ"
        ),
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )

    parser.add_argument(
        "-V",
        "--version",
        action="version",
        version=f"%(prog)s {__version__}",
    )

    parser.add_argument(
        "targets",
        nargs="*",
        default=[],
        help="ì˜ìƒ íŒŒì¼ ë˜ëŠ” ë””ë ‰í† ë¦¬ (ê¸°ë³¸: í˜„ì¬ ë””ë ‰í† ë¦¬)",
    )

    parser.add_argument(
        "-o",
        "--output",
        type=str,
        default=None,
        help="ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸: merged_output.mp4)",
    )

    parser.add_argument(
        "--no-resume",
        action="store_true",
        help="Resume ê¸°ëŠ¥ ë¹„í™œì„±í™”",
    )

    parser.add_argument(
        "--keep-temp",
        action="store_true",
        help="ì„ì‹œ íŒŒì¼ ë³´ì¡´ (ë””ë²„ê¹…ìš©)",
    )

    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ì‹¤í–‰ ê³„íšë§Œ ì¶œë ¥ (ì‹¤ì œ ì‹¤í–‰ ì•ˆ í•¨)",
    )

    parser.add_argument(
        "-v",
        "--verbose",
        action="store_true",
        help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥",
    )

    parser.add_argument(
        "--output-dir",
        type=str,
        default=None,
        help=f"ì¶œë ¥ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬ (í™˜ê²½ë³€ìˆ˜: {ENV_OUTPUT_DIR})",
    )

    # YouTube ì—…ë¡œë“œ ì˜µì…˜
    parser.add_argument(
        "--upload",
        action="store_true",
        help="ë³‘í•© ì™„ë£Œ í›„ YouTubeì— ì—…ë¡œë“œ",
    )

    parser.add_argument(
        "--upload-only",
        type=str,
        metavar="FILE",
        default=None,
        help="ì§€ì •ëœ íŒŒì¼ì„ YouTubeì— ì—…ë¡œë“œ (ë³‘í•© ì—†ì´)",
    )

    parser.add_argument(
        "--upload-title",
        type=str,
        default=None,
        help="YouTube ì—…ë¡œë“œ ì‹œ ì˜ìƒ ì œëª© (ê¸°ë³¸: íŒŒì¼ëª…)",
    )

    parser.add_argument(
        "--upload-privacy",
        type=str,
        default="unlisted",
        choices=["public", "unlisted", "private"],
        help="YouTube ê³µê°œ ì„¤ì • (ê¸°ë³¸: unlisted)",
    )

    parser.add_argument(
        "--playlist",
        type=str,
        action="append",
        default=None,
        metavar="ID",
        help=(f"ì—…ë¡œë“œ í›„ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (í™˜ê²½ë³€ìˆ˜: {ENV_YOUTUBE_PLAYLIST}, ì‰¼í‘œë¡œ êµ¬ë¶„)"),
    )

    parser.add_argument(
        "--upload-chunk",
        type=int,
        default=None,
        metavar="MB",
        help="ì—…ë¡œë“œ ì²­í¬ í¬ê¸° MB (1-256, í™˜ê²½ë³€ìˆ˜: TUBEARCHIVE_UPLOAD_CHUNK_MB, ê¸°ë³¸: 32)",
    )

    parser.add_argument(
        "--setup-youtube",
        action="store_true",
        help="YouTube ì¸ì¦ ìƒíƒœ í™•ì¸ ë° ì„¤ì • ê°€ì´ë“œ ì¶œë ¥",
    )

    parser.add_argument(
        "--youtube-auth",
        action="store_true",
        help="YouTube ë¸Œë¼ìš°ì € ì¸ì¦ ì‹¤í–‰",
    )

    parser.add_argument(
        "--list-playlists",
        action="store_true",
        help="ë‚´ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ëª©ë¡ ì¡°íšŒ",
    )

    parser.add_argument(
        "--parallel",
        "-j",
        type=int,
        default=None,
        metavar="N",
        help=f"ë³‘ë ¬ íŠ¸ëœìŠ¤ì½”ë”© ìˆ˜ (í™˜ê²½ë³€ìˆ˜: {ENV_PARALLEL}, ê¸°ë³¸: 1)",
    )

    parser.add_argument(
        "--reset-build",
        type=str,
        nargs="?",
        const="",
        metavar="PATH",
        help="íŠ¸ëœìŠ¤ì½”ë”©/ë³‘í•© ê¸°ë¡ ì´ˆê¸°í™” (ë‹¤ì‹œ ë¹Œë“œ, ê²½ë¡œ ì§€ì • ë˜ëŠ” ëª©ë¡ì—ì„œ ì„ íƒ)",
    )

    parser.add_argument(
        "--reset-upload",
        type=str,
        nargs="?",
        const="",
        metavar="PATH",
        help="YouTube ì—…ë¡œë“œ ê¸°ë¡ ì´ˆê¸°í™” (ë‹¤ì‹œ ì—…ë¡œë“œ, ê²½ë¡œ ì§€ì • ë˜ëŠ” ëª©ë¡ì—ì„œ ì„ íƒ)",
    )

    parser.add_argument(
        "--status",
        action="store_true",
        help="ì‘ì—… í˜„í™© ì¡°íšŒ (íŠ¸ëœìŠ¤ì½”ë”©, ë³‘í•©, ì—…ë¡œë“œ)",
    )

    parser.add_argument(
        "--status-detail",
        type=int,
        metavar="ID",
        default=None,
        help="íŠ¹ì • ì‘ì—… ìƒì„¸ ì¡°íšŒ (merge_job ID)",
    )

    return parser


def validate_args(args: argparse.Namespace) -> ValidatedArgs:
    """
    CLI ì¸ì ê²€ì¦.

    Args:
        args: íŒŒì‹±ëœ ì¸ì

    Returns:
        ê²€ì¦ëœ ì¸ì

    Raises:
        FileNotFoundError: íŒŒì¼/ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°
    """
    # targets ê²€ì¦
    targets: list[Path] = []
    if not args.targets:
        targets = [Path.cwd()]
    else:
        for target in args.targets:
            path = Path(target)
            if not path.exists():
                raise FileNotFoundError(f"Target not found: {target}")
            targets.append(path)

    # output ê²€ì¦
    output: Path | None = None
    if args.output:
        output = Path(args.output)
        if not output.parent.exists():
            raise FileNotFoundError(f"Output directory not found: {output.parent}")

    # output_dir ê²€ì¦ (CLI ì¸ì > í™˜ê²½ ë³€ìˆ˜ > None)
    output_dir: Path | None = None
    if args.output_dir:
        output_dir = Path(args.output_dir)
        if not output_dir.is_dir():
            raise FileNotFoundError(f"Output directory not found: {args.output_dir}")
    else:
        output_dir = get_default_output_dir()

    # upload í”Œë˜ê·¸ í™•ì¸
    upload = getattr(args, "upload", False)

    # parallel ê°’ ê²°ì • (CLI ì¸ì > í™˜ê²½ ë³€ìˆ˜ > ê¸°ë³¸ê°’)
    parallel = args.parallel if args.parallel is not None else get_default_parallel()
    if parallel < 1:
        parallel = 1

    return ValidatedArgs(
        targets=targets,
        output=output,
        output_dir=output_dir,
        no_resume=args.no_resume,
        keep_temp=args.keep_temp,
        dry_run=args.dry_run,
        upload=upload,
        parallel=parallel,
    )


def setup_logging(verbose: bool = False) -> None:
    """
    ë¡œê¹… ì„¤ì •.

    Args:
        verbose: ìƒì„¸ ë¡œê·¸ ì—¬ë¶€
    """
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
    )


def get_output_filename(targets: list[Path]) -> str:
    """
    ì…ë ¥ íƒ€ê²Ÿì—ì„œ ì¶œë ¥ íŒŒì¼ëª… ìƒì„±.

    ë””ë ‰í† ë¦¬ëª… ë˜ëŠ” ì²« ë²ˆì§¸ íŒŒì¼ì˜ ë¶€ëª¨ ë””ë ‰í† ë¦¬ëª…ì„ ì‚¬ìš©.

    Args:
        targets: ì…ë ¥ íƒ€ê²Ÿ ëª©ë¡

    Returns:
        ì¶œë ¥ íŒŒì¼ëª… (í™•ì¥ì í¬í•¨)
    """
    if not targets:
        return "output.mp4"

    first_target = targets[0]
    if first_target.is_dir():
        # ë””ë ‰í† ë¦¬ë©´ ë””ë ‰í† ë¦¬ëª… ì‚¬ìš©
        name = first_target.name
    else:
        # íŒŒì¼ì´ë©´ ë¶€ëª¨ ë””ë ‰í† ë¦¬ëª… ì‚¬ìš©
        name = first_target.parent.name

    # ë¹ˆ ì´ë¦„ì´ê±°ë‚˜ í˜„ì¬ ë””ë ‰í† ë¦¬ë©´ ê¸°ë³¸ê°’
    if not name or name == ".":
        name = "output"

    return f"{name}.mp4"


def handle_single_file_upload(
    video_file: VideoFile,
    args: ValidatedArgs,
) -> Path:
    """
    ë‹¨ì¼ íŒŒì¼ ì§ì ‘ ì—…ë¡œë“œ ì²˜ë¦¬.

    ì¸ì½”ë”©/ë³‘í•© ì—†ì´ DB ì €ì¥ í›„ ì›ë³¸ íŒŒì¼ ê²½ë¡œ ë°˜í™˜.

    Args:
        video_file: VideoFile ê°ì²´
        args: ê²€ì¦ëœ CLI ì¸ì

    Returns:
        ì›ë³¸ íŒŒì¼ ê²½ë¡œ
    """
    logger.info(f"Single file detected with --upload, skipping transcode: {video_file.path.name}")

    # 1. ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
    metadata = detect_metadata(video_file.path)

    # 2. YouTube ì œëª© ìƒì„± (ë””ë ‰í† ë¦¬ëª… ê¸°ë°˜)
    title = get_output_filename([video_file.path]).replace(".mp4", "")

    # 3. ì´¬ì˜ ì‹œê°„ ì¶”ì¶œ
    creation_time_str = video_file.creation_time.strftime("%H:%M:%S")

    # 4. í´ë¦½ ì •ë³´ ìƒì„±
    clip_info: dict[str, str | float | None] = {
        "name": video_file.path.name,
        "duration": metadata.duration_seconds,
        "start": 0.0,
        "end": metadata.duration_seconds,
        "device": metadata.device_model or "Unknown",
        "shot_time": creation_time_str,
    }

    # 5. YouTube ì„¤ëª… ìƒì„± (ë‹¨ì¼ íŒŒì¼ìš©)
    youtube_description = generate_single_file_description(clip_info)

    # 6. DB ì €ì¥
    conn = init_database()
    repo = MergeJobRepository(conn)
    today = date.today().isoformat()

    repo.create(
        output_path=video_file.path,
        video_ids=[],  # íŠ¸ëœìŠ¤ì½”ë”© ì•ˆ í•¨
        title=title,
        date=today,
        total_duration_seconds=metadata.duration_seconds,
        total_size_bytes=video_file.path.stat().st_size,
        clips_info_json=json.dumps([clip_info]),
        summary_markdown=youtube_description,
    )
    conn.close()

    # 7. ì½˜ì†” ì¶œë ¥
    logger.info(f"Saved to DB: {title}")
    print("\nğŸ“ ë‹¨ì¼ íŒŒì¼ ì—…ë¡œë“œ ëª¨ë“œ (íŠ¸ëœìŠ¤ì½”ë”© ìƒëµ)")
    print(f"ğŸ“¹ íŒŒì¼: {video_file.path.name}")
    minutes = int(metadata.duration_seconds // 60)
    seconds = int(metadata.duration_seconds % 60)
    print(f"â±ï¸  ê¸¸ì´: {minutes}ë¶„ {seconds}ì´ˆ")
    if metadata.device_model:
        print(f"ğŸ“· ê¸°ê¸°: {metadata.device_model}")

    return video_file.path


def _transcode_single(
    vf: VideoFile,
    temp_dir: Path,
    index: int,
) -> tuple[int, Path, int, tuple[str, float, str | None, str | None]]:
    """
    ë‹¨ì¼ íŒŒì¼ íŠ¸ëœìŠ¤ì½”ë”© (ë³‘ë ¬ ì²˜ë¦¬ìš©).

    Args:
        vf: VideoFile ê°ì²´
        temp_dir: ì„ì‹œ ë””ë ‰í† ë¦¬
        index: íŒŒì¼ ì¸ë±ìŠ¤ (ìˆœì„œ ìœ ì§€ìš©)

    Returns:
        (ì¸ë±ìŠ¤, ì¶œë ¥ ê²½ë¡œ, video_id, í´ë¦½ ì •ë³´) íŠœí”Œ
    """

    with Transcoder(temp_dir=temp_dir) as transcoder:
        output_path, video_id = transcoder.transcode_video(vf)

        # ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ (Summaryìš©)
        clip_info: tuple[str, float, str | None, str | None]
        try:
            metadata = detect_metadata(vf.path)
            creation_time_str = vf.creation_time.strftime("%H:%M:%S")
            clip_info = (
                vf.path.name,
                metadata.duration_seconds,
                metadata.device_model,
                creation_time_str,
            )
        except Exception as e:
            logger.warning(f"Failed to get metadata for {vf.path}: {e}")
            clip_info = (vf.path.name, 0.0, None, None)

        return index, output_path, video_id, clip_info


def run_pipeline(validated_args: ValidatedArgs) -> Path:
    """
    ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰.

    Args:
        validated_args: ê²€ì¦ëœ ì¸ì

    Returns:
        ìµœì¢… ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    """
    # 1. íŒŒì¼ ìŠ¤ìº”
    logger.info("Scanning video files...")
    video_files = scan_videos(validated_args.targets)

    if not video_files:
        logger.error("No video files found")
        raise ValueError("No video files found")

    logger.info(f"Found {len(video_files)} video files")
    for vf in video_files:
        logger.info(f"  - {vf.path.name}")

    # ë‹¨ì¼ íŒŒì¼ + --upload ì‹œ ë¹ ë¥¸ ê²½ë¡œ (ì¸ì½”ë”©/ë³‘í•© ê±´ë„ˆë›°ê¸°)
    if len(video_files) == 1 and validated_args.upload:
        return handle_single_file_upload(video_files[0], validated_args)

    # 2. íŠ¸ëœìŠ¤ì½”ë”© (ì„ì‹œ íŒŒì¼ì€ /tmpì— ì €ì¥)
    temp_dir = get_temp_dir()
    logger.info(f"Using temp directory: {temp_dir}")

    parallel = validated_args.parallel
    if parallel > 1:
        logger.info(f"Starting parallel transcoding (workers: {parallel})...")
    else:
        logger.info("Starting transcoding...")

    # ê²°ê³¼ ì €ì¥ìš© (ì¸ë±ìŠ¤ë¡œ ìˆœì„œ ìœ ì§€): (ì¶œë ¥ ê²½ë¡œ, video_id, í´ë¦½ ì •ë³´)
    results: dict[int, tuple[Path, int, tuple[str, float, str | None, str | None]]] = {}

    if parallel > 1:
        # ë³‘ë ¬ ì²˜ë¦¬
        completed_count = 0
        total_count = len(video_files)
        print_lock = Lock()

        def print_progress(idx: int, filename: str, status: str) -> None:
            nonlocal completed_count
            with print_lock:
                completed_count += 1
                print(
                    f"\rğŸ¬ íŠ¸ëœìŠ¤ì½”ë”©: [{completed_count}/{total_count}] {status}: {filename}",
                    end="",
                    flush=True,
                )
                if completed_count == total_count:
                    print()  # ì¤„ë°”ê¿ˆ

        with ThreadPoolExecutor(max_workers=parallel) as executor:
            futures = {
                executor.submit(_transcode_single, vf, temp_dir, i): i
                for i, vf in enumerate(video_files)
            }

            for future in as_completed(futures):
                try:
                    idx, output_path, video_id, clip_info = future.result()
                    results[idx] = (output_path, video_id, clip_info)
                    print_progress(idx, video_files[idx].path.name, "ì™„ë£Œ")
                except Exception as e:
                    idx = futures[future]
                    logger.error(f"Failed to transcode {video_files[idx].path}: {e}")
                    print_progress(idx, video_files[idx].path.name, "ì‹¤íŒ¨")
                    raise

    else:
        # ìˆœì°¨ ì²˜ë¦¬ (ê¸°ì¡´ ë°©ì‹)
        progress = MultiProgressBar(total_files=len(video_files))

        with Transcoder(temp_dir=temp_dir) as transcoder:
            for i, vf in enumerate(video_files):
                progress.start_file(vf.path.name)

                # ìƒì„¸ ì§„í–‰ë¥  ì½œë°±
                def on_progress_info(info: ProgressInfo) -> None:
                    progress.update_with_info(info)

                output_path, video_id = transcoder.transcode_video(
                    vf,
                    progress_info_callback=on_progress_info,
                )

                # ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ (Summaryìš©)
                try:
                    metadata = detect_metadata(vf.path)
                    creation_time_str = vf.creation_time.strftime("%H:%M:%S")
                    clip_info = (
                        vf.path.name,
                        metadata.duration_seconds,
                        metadata.device_model,
                        creation_time_str,
                    )
                except Exception as e:
                    logger.warning(f"Failed to get metadata for {vf.path}: {e}")
                    clip_info = (vf.path.name, 0.0, None, None)

                results[i] = (output_path, video_id, clip_info)
                progress.finish_file()

    # ì¸ë±ìŠ¤ ìˆœì„œëŒ€ë¡œ ê²°ê³¼ ì •ë ¬
    transcoded_paths: list[Path] = []
    video_ids: list[int] = []
    video_clips: list[tuple[str, float, str | None, str | None]] = []
    for i in range(len(video_files)):
        output_path, video_id, clip_info = results[i]
        transcoded_paths.append(output_path)
        video_ids.append(video_id)
        video_clips.append(clip_info)

    # 3. ë³‘í•©
    logger.info("Merging videos...")

    # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ê²°ì •
    if validated_args.output:
        output_path = validated_args.output
    else:
        output_filename = get_output_filename(validated_args.targets)
        output_dir = validated_args.output_dir or Path.cwd()
        output_path = output_dir / output_filename

    merger = Merger(temp_dir=temp_dir)
    final_path = merger.merge(transcoded_paths, output_path)

    logger.info(f"Final output: {final_path}")

    # 4. DBì— íƒ€ì„ë¼ì¸ ì •ë³´ ì €ì¥ ë° Summary ìƒì„±
    summary_markdown = save_merge_job_to_db(
        final_path, video_clips, validated_args.targets, video_ids
    )

    # 5. ì„ì‹œ íŒŒì¼ ë° í´ë” ì •ë¦¬
    if not validated_args.keep_temp:
        logger.info("Cleaning up temporary files...")
        for temp_path in transcoded_paths:
            if temp_path.exists() and temp_path != final_path:
                temp_path.unlink()
                logger.debug(f"  Removed: {temp_path}")

        # ì„ì‹œ í´ë” ì‚­ì œ (ë¹„ì–´ìˆê±°ë‚˜ concat íŒŒì¼ë§Œ ë‚¨ì€ ê²½ìš°)
        if temp_dir.exists():
            try:
                shutil.rmtree(temp_dir)
                logger.info(f"Removed temp directory: {temp_dir}")
            except OSError as e:
                logger.warning(f"Failed to remove temp directory: {e}")

    # 6. Summary ì¶œë ¥ (ë³µì‚¬í•´ì„œ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥)
    if summary_markdown:
        print("\n" + "=" * 60)
        print("ğŸ“‹ SUMMARY (Copy & Paste)")
        print("=" * 60)
        print(summary_markdown)
        print("=" * 60 + "\n")

    return final_path


def save_merge_job_to_db(
    output_path: Path,
    video_clips: list[tuple[str, float, str | None, str | None]],
    targets: list[Path],
    video_ids: list[int],
) -> str | None:
    """
    ë³‘í•© ì‘ì—… ì •ë³´ë¥¼ DBì— ì €ì¥ (íƒ€ì„ë¼ì¸ ë° Summary í¬í•¨).

    Args:
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        video_clips: (íŒŒì¼ëª…, ì¬ìƒì‹œê°„, ê¸°ì¢…, ì´¬ì˜ì‹œê°„) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        targets: ëŒ€ìƒ ê²½ë¡œ ëª©ë¡
        video_ids: ë³‘í•©ëœ ì˜ìƒë“¤ì˜ DB ID ëª©ë¡
        targets: ì…ë ¥ íƒ€ê²Ÿ ëª©ë¡ (ì œëª© ì¶”ì¶œìš©)

    Returns:
        ìƒì„±ëœ Summary ë§ˆí¬ë‹¤ìš´ (ì‹¤íŒ¨ ì‹œ None)
    """
    from tubearchive.utils.summary_generator import (
        generate_clip_summary,
        generate_youtube_description,
    )

    try:
        conn = init_database()
        repo = MergeJobRepository(conn)

        # íƒ€ì„ë¼ì¸ ì •ë³´ ìƒì„± (ê° í´ë¦½ì˜ ë©”íƒ€ë°ì´í„° í¬í•¨)
        timeline: list[dict[str, str | float | None]] = []
        current_time = 0.0
        for name, duration, device, shot_time in video_clips:
            timeline.append(
                {
                    "name": name,
                    "duration": duration,
                    "start": current_time,
                    "end": current_time + duration,
                    "device": device,
                    "shot_time": shot_time,
                }
            )
            current_time += duration

        clips_json = json.dumps(timeline, ensure_ascii=False)

        # ì œëª©: ë””ë ‰í† ë¦¬ëª…
        title = None
        if targets:
            first_target = targets[0]
            if first_target.is_dir():
                title = first_target.name
            else:
                title = first_target.parent.name
            if not title or title == ".":
                title = output_path.stem

        # ë‚ ì§œ: ì˜¤ëŠ˜
        today = date.today().isoformat()

        # ì´ ì¬ìƒì‹œê°„ ë° íŒŒì¼ í¬ê¸°
        total_duration = sum(d for _, d, _, _ in video_clips)
        total_size = output_path.stat().st_size if output_path.exists() else 0

        # ì½˜ì†” ì¶œë ¥ìš© ìš”ì•½ (ë§ˆí¬ë‹¤ìš´ í˜•ì‹)
        console_summary = generate_clip_summary(video_clips)

        # YouTube ì„¤ëª…ìš© (íƒ€ì„ìŠ¤íƒ¬í”„ + ì´¬ì˜ê¸°ê¸°)
        youtube_description = generate_youtube_description(video_clips)

        repo.create(
            output_path=output_path,
            video_ids=video_ids,
            title=title,
            date=today,
            total_duration_seconds=total_duration,
            total_size_bytes=total_size,
            clips_info_json=clips_json,
            summary_markdown=youtube_description,  # YouTube ì„¤ëª…ìš©ìœ¼ë¡œ ì €ì¥
        )
        conn.close()
        logger.debug("Merge job saved to database with summary")
        return console_summary  # ì½˜ì†”ì—ëŠ” ìƒì„¸ ìš”ì•½ ì¶œë ¥

    except Exception as e:
        logger.warning(f"Failed to save merge job to DB: {e}")
        return None


def upload_to_youtube(
    file_path: Path,
    title: str | None = None,
    description: str = "",
    privacy: str = "unlisted",
    merge_job_id: int | None = None,
    playlist_ids: list[str] | None = None,
    chunk_mb: int | None = None,
) -> None:
    """
    ì˜ìƒì„ YouTubeì— ì—…ë¡œë“œ.

    Args:
        file_path: ì—…ë¡œë“œí•  ì˜ìƒ íŒŒì¼ ê²½ë¡œ
        title: ì˜ìƒ ì œëª© (Noneì´ë©´ íŒŒì¼ëª… ì‚¬ìš©)
        description: ì˜ìƒ ì„¤ëª…
        privacy: ê³µê°œ ì„¤ì • (public, unlisted, private)
        merge_job_id: DBì— ì €ì¥í•  MergeJob ID
        playlist_ids: ì¶”ê°€í•  í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ì¶”ê°€ ì•ˆ í•¨)
        chunk_mb: ì—…ë¡œë“œ ì²­í¬ í¬ê¸° MB (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜/ê¸°ë³¸ê°’)
    """
    from tubearchive.youtube.auth import YouTubeAuthError, get_authenticated_service
    from tubearchive.youtube.playlist import PlaylistError, add_to_playlist
    from tubearchive.youtube.uploader import (
        YouTubeUploader,
        YouTubeUploadError,
        validate_upload,
    )

    if not file_path.exists():
        raise FileNotFoundError(f"Video file not found: {file_path}")

    # ì—…ë¡œë“œ ê°€ëŠ¥ ì—¬ë¶€ ê²€ì¦
    validation = validate_upload(file_path)
    print(f"\n{validation.get_summary()}")

    if not validation.is_valid:
        print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
        print("   - ì˜ìƒì„ ë” ì‘ì€ íŒŒíŠ¸ë¡œ ë¶„í• í•˜ì—¬ ì—…ë¡œë“œ")
        print("   - ë¹„íŠ¸ë ˆì´íŠ¸ë¥¼ ë‚®ì¶° ì¬ì¸ì½”ë”©")
        raise YouTubeUploadError("Video exceeds YouTube limits")

    if validation.warnings:
        # ê²½ê³ ê°€ ìˆìœ¼ë©´ ì‚¬ìš©ì í™•ì¸
        try:
            response = safe_input("\nê³„ì† ì—…ë¡œë“œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").lower()
            if response not in ("y", "yes"):
                print("ì—…ë¡œë“œê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                return
        except KeyboardInterrupt:
            print("\nì—…ë¡œë“œê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return

    # ì œëª© ê²°ì •: ì§€ì •ê°’ > íŒŒì¼ëª…(í™•ì¥ì ì œì™¸)
    # YYYYMMDD í˜•ì‹ì„ 'YYYYë…„ Mì›” Dì¼'ë¡œ ë³€í™˜
    raw_title = title or file_path.stem
    video_title = format_youtube_title(raw_title)

    logger.info(f"Uploading to YouTube: {file_path}")
    logger.info(f"  Title: {video_title}")
    logger.info(f"  Privacy: {privacy}")

    # ì¸ì¦ ìƒíƒœ í™•ì¸
    from tubearchive.youtube.auth import check_auth_status

    status = check_auth_status()

    if not status.has_client_secrets:
        print("\nâŒ YouTube ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        print(f"\n{status.get_setup_guide()}")
        print("\nì„¤ì • ì™„ë£Œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        raise YouTubeAuthError("client_secrets.json not found")

    if not status.has_valid_token:
        print("\nğŸ” YouTube ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        print("   ë¸Œë¼ìš°ì €ì—ì„œ Google ê³„ì • ì¸ì¦ì„ ì§„í–‰í•©ë‹ˆë‹¤...\n")

    try:
        # ì¸ì¦ (í† í° ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ë¸Œë¼ìš°ì € ì—´ë¦¼)
        service = get_authenticated_service()

        # ì—…ë¡œë“œ
        uploader = YouTubeUploader(service, chunk_mb=chunk_mb)

        # í”„ë¡œê·¸ë ˆìŠ¤ ë°” ì„¤ì •
        file_size_bytes = file_path.stat().st_size
        file_size_mb = file_size_bytes / (1024 * 1024)
        bar_width = 30
        last_percent = -1

        def on_progress(percent: int) -> None:
            nonlocal last_percent
            if percent == last_percent:
                return  # ì¤‘ë³µ ì—…ë°ì´íŠ¸ ë°©ì§€
            last_percent = percent

            filled = int(bar_width * percent / 100)
            bar = "â–ˆ" * filled + "â–‘" * (bar_width - filled)
            uploaded_mb = file_size_mb * percent / 100
            # ì¤„ ì „ì²´ë¥¼ ì§€ìš°ê³  ë‹¤ì‹œ ì¶œë ¥ (\033[K: ì»¤ì„œë¶€í„° ì¤„ ëê¹Œì§€ ì§€ì›€)
            sys.stdout.write(
                f"\r\033[KğŸ“¤ [{bar}] {percent:3d}% ({uploaded_mb:.1f}/{file_size_mb:.1f}MB)"
            )
            sys.stdout.flush()
            if percent >= 100:
                sys.stdout.write("\n")
                sys.stdout.flush()

        result = uploader.upload(
            file_path=file_path,
            title=video_title,
            description=description,
            privacy=privacy,
            on_progress=on_progress,
        )

        print("\nâœ… YouTube ì—…ë¡œë“œ ì™„ë£Œ!")
        print(f"ğŸ¬ URL: {result.url}")

        # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        if playlist_ids:
            for pid in playlist_ids:
                try:
                    item_id = add_to_playlist(service, pid, result.video_id)
                    print(f"ğŸ“‹ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ë¨: {pid} (item: {item_id})")
                except PlaylistError as e:
                    logger.warning(f"Failed to add to playlist {pid}: {e}")
                    print(f"âš ï¸ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì¶”ê°€ ì‹¤íŒ¨ ({pid}): {e}")

        # DBì— YouTube ID ì €ì¥
        if merge_job_id is not None:
            try:
                conn = init_database()
                repo = MergeJobRepository(conn)
                repo.update_youtube_id(merge_job_id, result.video_id)
                conn.close()
                logger.debug(f"YouTube ID {result.video_id} saved to merge job {merge_job_id}")
            except Exception as e:
                logger.warning(f"Failed to save YouTube ID to DB: {e}")

    except YouTubeAuthError as e:
        logger.error(f"YouTube authentication failed: {e}")
        print(f"\nâŒ YouTube ì¸ì¦ ì‹¤íŒ¨: {e}")
        print("\nì„¤ì • ê°€ì´ë“œ: tubearchive --setup-youtube")
        raise
    except YouTubeUploadError as e:
        logger.error(f"YouTube upload failed: {e}")
        print(f"\nâŒ YouTube ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise


def cmd_setup_youtube() -> None:
    """
    --setup-youtube ì˜µì…˜ ì²˜ë¦¬.

    YouTube ì¸ì¦ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ì„¤ì • ê°€ì´ë“œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    from tubearchive.youtube.auth import check_auth_status

    print("\nğŸ¬ YouTube ì—…ë¡œë“œ ì„¤ì • ìƒíƒœ\n")
    print("=" * 50)

    status = check_auth_status()
    print(status.get_setup_guide())

    print("=" * 50)

    # ë¸Œë¼ìš°ì € ì¸ì¦ì´ í•„ìš”í•˜ë©´ ë°”ë¡œ ì‹¤í–‰ ì œì•ˆ
    if status.needs_browser_auth:
        print("\nğŸ’¡ ì§€ê¸ˆ ë°”ë¡œ ì¸ì¦í•˜ë ¤ë©´:")
        print("   tubearchive --youtube-auth")
        print("   (ë¸Œë¼ìš°ì €ê°€ ì—´ë¦¬ë©° Google ê³„ì • ì¸ì¦ì´ ì§„í–‰ë©ë‹ˆë‹¤)")


def cmd_youtube_auth() -> None:
    """
    --youtube-auth ì˜µì…˜ ì²˜ë¦¬.

    ë¸Œë¼ìš°ì €ë¥¼ ì—´ì–´ YouTube OAuth ì¸ì¦ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    from tubearchive.youtube.auth import (
        YouTubeAuthError,
        check_auth_status,
        get_client_secrets_path,
        get_token_path,
        run_auth_flow,
        save_credentials,
    )

    print("\nğŸ” YouTube ì¸ì¦ ì‹œì‘\n")

    # ë¨¼ì € ìƒíƒœ í™•ì¸
    status = check_auth_status()

    if status.has_valid_token:
        print("âœ… ì´ë¯¸ ì¸ì¦ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")
        print(f"   í† í° ìœ„ì¹˜: {status.token_path}")
        return

    if not status.has_client_secrets:
        print("âŒ client_secrets.jsonì´ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   í•„ìš”í•œ ìœ„ì¹˜: {status.client_secrets_path}")
        print("\nì„¤ì • ê°€ì´ë“œë¥¼ ë³´ë ¤ë©´: tubearchive --setup-youtube")
        raise YouTubeAuthError("client_secrets.json not found")

    # ë¸Œë¼ìš°ì € ì¸ì¦ ì‹¤í–‰
    print("ğŸŒ ë¸Œë¼ìš°ì €ì—ì„œ Google ê³„ì • ì¸ì¦ì„ ì§„í–‰í•©ë‹ˆë‹¤...")
    print("   (ë¸Œë¼ìš°ì €ê°€ ìë™ìœ¼ë¡œ ì—´ë¦½ë‹ˆë‹¤)\n")

    try:
        secrets_path = get_client_secrets_path()
        token_path = get_token_path()

        credentials = run_auth_flow(secrets_path)
        save_credentials(credentials, token_path)

        print("\nâœ… ì¸ì¦ ì™„ë£Œ!")
        print(f"   í† í° ì €ì¥ë¨: {token_path}")
        print("\nì´ì œ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
        print("   tubearchive --upload ~/Videos/")
        print("   tubearchive --upload-only video.mp4")

    except Exception as e:
        logger.error(f"YouTube authentication failed: {e}")
        print(f"\nâŒ ì¸ì¦ ì‹¤íŒ¨: {e}")
        raise


def cmd_list_playlists() -> None:
    """
    --list-playlists ì˜µì…˜ ì²˜ë¦¬.

    ë‚´ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ëª©ë¡ì„ ì¡°íšŒí•˜ì—¬ IDì™€ í•¨ê»˜ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    from tubearchive.youtube.auth import get_authenticated_service
    from tubearchive.youtube.playlist import list_playlists

    print("\nğŸ“‹ ë‚´ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ëª©ë¡\n")

    try:
        service = get_authenticated_service()
        playlists = list_playlists(service)

        if not playlists:
            print("í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"{'ë²ˆí˜¸':<4} {'ì œëª©':<40} {'ì˜ìƒìˆ˜':<8} ID")
        print("-" * 80)
        for i, pl in enumerate(playlists, 1):
            print(f"{i:<4} {pl.title:<40} {pl.item_count:<8} {pl.id}")

        print("-" * 80)
        print("\nğŸ’¡ í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì˜ˆì‹œ:")
        print(f"   export {ENV_YOUTUBE_PLAYLIST}={playlists[0].id}")
        if len(playlists) > 1:
            ids = ",".join(pl.id for pl in playlists[:2])
            print(f"   export {ENV_YOUTUBE_PLAYLIST}={ids}  # ì—¬ëŸ¬ ê°œ")

    except Exception as e:
        logger.error(f"Failed to list playlists: {e}")
        print(f"\nâŒ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")

        # ìŠ¤ì½”í”„ ë¶€ì¡± ì—ëŸ¬ ì²˜ë¦¬
        if "insufficient" in str(e).lower() or "scope" in str(e).lower():
            from tubearchive.youtube.auth import get_token_path

            token_path = get_token_path()
            print("\nğŸ’¡ ê¶Œí•œì´ ë¶€ì¡±í•©ë‹ˆë‹¤. í† í°ì„ ì‚­ì œí•˜ê³  ì¬ì¸ì¦í•˜ì„¸ìš”:")
            print(f"   rm {token_path}")
            print("   tubearchive --youtube-auth")
        raise


def cmd_reset_build(path_arg: str) -> None:
    """
    --reset-build ì˜µì…˜ ì²˜ë¦¬.

    ë³‘í•© ê¸°ë¡ì„ ì‚­ì œí•˜ì—¬ ë‹¤ì‹œ ë¹Œë“œí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

    Args:
        path_arg: íŒŒì¼ ê²½ë¡œ (ë¹ˆ ë¬¸ìì—´ì´ë©´ ëª©ë¡ì—ì„œ ì„ íƒ)
    """
    conn = init_database()
    repo = MergeJobRepository(conn)

    if path_arg:
        # ê²½ë¡œê°€ ì§€ì •ëœ ê²½ìš° í•´ë‹¹ ê²½ë¡œì˜ ë ˆì½”ë“œ ì‚­ì œ
        target_path = Path(path_arg).resolve()
        deleted = repo.delete_by_output_path(target_path)
        if deleted > 0:
            print(f"âœ… ë¹Œë“œ ê¸°ë¡ ì‚­ì œë¨: {target_path}")
            print("   ì´ì œ ë‹¤ì‹œ ë¹Œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            print(f"âš ï¸ í•´ë‹¹ ê²½ë¡œì˜ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤: {target_path}")
    else:
        # ëª©ë¡ì—ì„œ ì„ íƒ
        jobs = repo.get_all()
        if not jobs:
            print("ğŸ“‹ ë¹Œë“œ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
            conn.close()
            return

        print("\nğŸ“‹ ë¹Œë“œ ê¸°ë¡ ëª©ë¡")
        print("=" * 80)
        print(f"{'ë²ˆí˜¸':<4} {'ì œëª©':<30} {'ë‚ ì§œ':<12} {'YouTube':<10} ê²½ë¡œ")
        print("-" * 80)
        for i, job in enumerate(jobs, 1):
            title = (job.title or "-")[:28]
            date = job.date or "-"
            yt_status = "âœ… ì—…ë¡œë“œë¨" if job.youtube_id else "-"
            path = str(job.output_path)
            if len(path) > 40:
                path = "..." + path[-37:]
            print(f"{i:<4} {title:<30} {date:<12} {yt_status:<10} {path}")
        print("=" * 80)

        try:
            choice = safe_input("\nì‚­ì œí•  ë²ˆí˜¸ ì…ë ¥ (0: ì·¨ì†Œ): ")
            if not choice or choice == "0":
                print("ì·¨ì†Œë¨")
                conn.close()
                return

            idx = int(choice) - 1
            if 0 <= idx < len(jobs):
                job = jobs[idx]
                if job.id is not None:
                    repo.delete(job.id)
                print(f"\nâœ… ë¹Œë“œ ê¸°ë¡ ì‚­ì œë¨: {job.title or job.output_path}")
                print("   ì´ì œ ë‹¤ì‹œ ë¹Œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                print("ì˜ëª»ëœ ë²ˆí˜¸ì…ë‹ˆë‹¤.")
        except ValueError:
            print("ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        except KeyboardInterrupt:
            print("\nì·¨ì†Œë¨")

    conn.close()


def cmd_reset_upload(path_arg: str) -> None:
    """
    --reset-upload ì˜µì…˜ ì²˜ë¦¬.

    YouTube ì—…ë¡œë“œ ê¸°ë¡ì„ ì´ˆê¸°í™”í•˜ì—¬ ë‹¤ì‹œ ì—…ë¡œë“œí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

    Args:
        path_arg: íŒŒì¼ ê²½ë¡œ (ë¹ˆ ë¬¸ìì—´ì´ë©´ ëª©ë¡ì—ì„œ ì„ íƒ)
    """
    conn = init_database()
    repo = MergeJobRepository(conn)

    if path_arg:
        # ê²½ë¡œê°€ ì§€ì •ëœ ê²½ìš° í•´ë‹¹ ê²½ë¡œì˜ ë ˆì½”ë“œ ì´ˆê¸°í™”
        target_path = Path(path_arg).resolve()
        cursor = conn.execute(
            "SELECT id, youtube_id FROM merge_jobs WHERE output_path = ?",
            (str(target_path),),
        )
        row = cursor.fetchone()
        if row and row["youtube_id"]:
            repo.clear_youtube_id(row["id"])
            print(f"âœ… ì—…ë¡œë“œ ê¸°ë¡ ì´ˆê¸°í™”ë¨: {target_path}")
            print(f"   ì´ì „ YouTube ID: {row['youtube_id']}")
            print("   ì´ì œ ë‹¤ì‹œ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        elif row:
            print(f"âš ï¸ ì´ë¯¸ ì—…ë¡œë“œ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤: {target_path}")
        else:
            print(f"âš ï¸ í•´ë‹¹ ê²½ë¡œì˜ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤: {target_path}")
    else:
        # ì—…ë¡œë“œëœ ëª©ë¡ì—ì„œ ì„ íƒ
        jobs = repo.get_uploaded()
        if not jobs:
            print("ğŸ“‹ ì—…ë¡œë“œëœ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
            conn.close()
            return

        print("\nğŸ“‹ ì—…ë¡œë“œëœ ì˜ìƒ ëª©ë¡")
        print("=" * 90)
        print(f"{'ë²ˆí˜¸':<4} {'ì œëª©':<30} {'ë‚ ì§œ':<12} {'YouTube ID':<15} ê²½ë¡œ")
        print("-" * 90)
        for i, job in enumerate(jobs, 1):
            title = (job.title or "-")[:28]
            date = job.date or "-"
            yt_id = job.youtube_id or "-"
            path = str(job.output_path)
            if len(path) > 30:
                path = "..." + path[-27:]
            print(f"{i:<4} {title:<30} {date:<12} {yt_id:<15} {path}")
        print("=" * 90)

        try:
            choice = safe_input("\nì´ˆê¸°í™”í•  ë²ˆí˜¸ ì…ë ¥ (0: ì·¨ì†Œ): ")
            if not choice or choice == "0":
                print("ì·¨ì†Œë¨")
                conn.close()
                return

            idx = int(choice) - 1
            if 0 <= idx < len(jobs):
                job = jobs[idx]
                if job.id is not None:
                    repo.clear_youtube_id(job.id)
                print(f"\nâœ… ì—…ë¡œë“œ ê¸°ë¡ ì´ˆê¸°í™”ë¨: {job.title or job.output_path}")
                print(f"   ì´ì „ YouTube ID: {job.youtube_id}")
                print("   ì´ì œ ë‹¤ì‹œ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                print("ì˜ëª»ëœ ë²ˆí˜¸ì…ë‹ˆë‹¤.")
        except ValueError:
            print("ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        except KeyboardInterrupt:
            print("\nì·¨ì†Œë¨")

    conn.close()


def resolve_playlist_ids(playlist_args: list[str] | None) -> list[str]:
    """
    í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì¸ì ì²˜ë¦¬.

    ìš°ì„ ìˆœìœ„:
    1. --playlist ì˜µì…˜ì´ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •ë¨ â†’ í•´ë‹¹ ê°’ ì‚¬ìš©
    2. --playlist ì˜µì…˜ ì—†ìŒ + í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ë¨ â†’ í™˜ê²½ ë³€ìˆ˜ ê°’ ì‚¬ìš©
    3. ë‘˜ ë‹¤ ì—†ìŒ â†’ ë¹ˆ ë¦¬ìŠ¤íŠ¸ (í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì¶”ê°€ ì•ˆ í•¨)

    Args:
        playlist_args: --playlist ì¸ì ê°’ ë¦¬ìŠ¤íŠ¸
            - None: í™˜ê²½ ë³€ìˆ˜ í™•ì¸
            - ë¹ˆ ë¬¸ìì—´ í¬í•¨: ëª©ë¡ì—ì„œ ì„ íƒ
            - ê¸°íƒ€: í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ IDë¡œ ì‚¬ìš©

    Returns:
        í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID ë¦¬ìŠ¤íŠ¸ (ì‚¬ìš© ì•ˆ í•¨ ë˜ëŠ” ì·¨ì†Œ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸)
    """
    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê¸°ë³¸ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ í™•ì¸
    if playlist_args is None:
        env_playlist = os.environ.get(ENV_YOUTUBE_PLAYLIST)
        if env_playlist:
            ids = [pid.strip() for pid in env_playlist.split(",") if pid.strip()]
            if ids:
                logger.info(f"Using playlists from env: {ids}")
                return ids
        return []

    # ë¹ˆ ë¬¸ìì—´ì´ ìˆìœ¼ë©´ ì„ íƒ ëª¨ë“œ
    needs_selection = any(arg == "" for arg in playlist_args)
    direct_ids = [arg for arg in playlist_args if arg and arg != ""]

    if needs_selection:
        # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ëª©ë¡ì—ì„œ ì„ íƒ
        from tubearchive.youtube.auth import get_authenticated_service
        from tubearchive.youtube.playlist import list_playlists, select_playlist_interactive

        print("\nğŸ“‹ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        service = get_authenticated_service()
        playlists = list_playlists(service)

        selected = select_playlist_interactive(playlists)
        if selected:
            for pl in selected:
                print(f"   ì„ íƒë¨: {pl.title}")
            direct_ids.extend([pl.id for pl in selected])

    return direct_ids


def cmd_upload_only(args: argparse.Namespace) -> None:
    """
    --upload-only ì˜µì…˜ ì²˜ë¦¬.

    Args:
        args: íŒŒì‹±ëœ ì¸ì
    """
    file_path = Path(args.upload_only)

    if not file_path.exists():
        logger.error(f"File not found: {file_path}")
        sys.exit(1)

    # DBì—ì„œ MergeJob ì¡°íšŒ (ê²½ë¡œë¡œ ì°¾ê¸°)
    merge_job_id = None
    description = ""

    try:
        conn = init_database()

        # ìµœì‹  MergeJobì—ì„œ ì¼ì¹˜í•˜ëŠ” ê²½ë¡œ ì°¾ê¸°
        cursor = conn.execute(
            """SELECT id, summary_markdown FROM merge_jobs
            WHERE output_path = ? ORDER BY created_at DESC LIMIT 1""",
            (str(file_path),),
        )
        row = cursor.fetchone()
        if row:
            merge_job_id = row["id"]
            # descriptionì´ ë¹„ì–´ìˆìœ¼ë©´ summary_markdown ì‚¬ìš©
            if row["summary_markdown"]:
                description = row["summary_markdown"]
                logger.info("Using summary from database as description")

        conn.close()
    except Exception as e:
        logger.warning(f"Failed to load merge job from DB: {e}")

    # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
    playlist_ids = resolve_playlist_ids(args.playlist)

    # ì—…ë¡œë“œ ì‹¤í–‰
    upload_to_youtube(
        file_path=file_path,
        title=args.upload_title,
        description=description,
        privacy=args.upload_privacy,
        merge_job_id=merge_job_id,
        playlist_ids=playlist_ids,
        chunk_mb=args.upload_chunk,
    )


def cmd_status() -> None:
    """
    --status ì˜µì…˜ ì²˜ë¦¬.

    ì‘ì—… í˜„í™©ì„ ì¡°íšŒí•˜ì—¬ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    conn = init_database()

    print("\nğŸ“Š TubeArchive ì‘ì—… í˜„í™©\n")

    # 1. ì§„í–‰ ì¤‘ì¸ íŠ¸ëœìŠ¤ì½”ë”© ì‘ì—…
    cursor = conn.execute("""
        SELECT tj.id, tj.status, tj.progress_percent, v.original_path
        FROM transcoding_jobs tj
        JOIN videos v ON tj.video_id = v.id
        WHERE tj.status IN ('pending', 'processing')
        ORDER BY tj.created_at DESC
        LIMIT 10
    """)
    processing_jobs = cursor.fetchall()

    if processing_jobs:
        print("ğŸ”„ ì§„í–‰ ì¤‘ì¸ íŠ¸ëœìŠ¤ì½”ë”©:")
        print("-" * 70)
        for job in processing_jobs:
            path = Path(job["original_path"]).name
            status = "â³ ëŒ€ê¸°" if job["status"] == "pending" else "ğŸ”„ ì§„í–‰"
            progress = job["progress_percent"] or 0
            print(f"  {status} [{progress:3d}%] {path}")
        print()

    # 2. ìµœê·¼ ë³‘í•© ì‘ì—…
    cursor = conn.execute("""
        SELECT id, title, date, status, youtube_id, output_path,
               total_duration_seconds, total_size_bytes, created_at
        FROM merge_jobs
        ORDER BY created_at DESC
        LIMIT 10
    """)
    merge_jobs = cursor.fetchall()

    if merge_jobs:
        print("ğŸ“ ìµœê·¼ ë³‘í•© ì‘ì—…:")
        print("-" * 90)
        print(f"{'ID':<4} {'ìƒíƒœ':<10} {'ì œëª©':<25} {'ë‚ ì§œ':<12} {'ê¸¸ì´':<10} {'YouTube':<12}")
        print("-" * 90)
        for job in merge_jobs:
            job_id = job["id"]
            title = (job["title"] or "-")[:23]
            date = job["date"] or "-"
            status = job["status"]

            # ìƒíƒœ ì•„ì´ì½˜
            status_icon = {
                "pending": "â³ ëŒ€ê¸°",
                "processing": "ğŸ”„ ì§„í–‰",
                "completed": "âœ… ì™„ë£Œ",
                "failed": "âŒ ì‹¤íŒ¨",
            }.get(status, status)

            # ê¸¸ì´ í¬ë§·
            duration = job["total_duration_seconds"] or 0
            if duration >= 3600:
                duration_str = f"{int(duration // 3600)}h {int((duration % 3600) // 60)}m"
            elif duration >= 60:
                duration_str = f"{int(duration // 60)}m {int(duration % 60)}s"
            else:
                duration_str = f"{int(duration)}s"

            # YouTube ìƒíƒœ
            if job["youtube_id"]:
                yt_status = f"âœ… {job['youtube_id'][:8]}..."
            else:
                yt_status = "- ë¯¸ì—…ë¡œë“œ"

            row = f"{job_id:<4} {status_icon:<10} {title:<25} {date:<12} {duration_str:<10}"
            print(f"{row} {yt_status}")

        print("-" * 90)
    else:
        print("ğŸ“ ë³‘í•© ì‘ì—… ì—†ìŒ\n")

    # 3. í†µê³„ ìš”ì•½
    cursor = conn.execute("SELECT COUNT(*) as cnt FROM videos")
    video_count = cursor.fetchone()["cnt"]

    cursor = conn.execute("SELECT COUNT(*) as cnt FROM merge_jobs WHERE youtube_id IS NOT NULL")
    uploaded_count = cursor.fetchone()["cnt"]

    cursor = conn.execute("SELECT COUNT(*) as cnt FROM merge_jobs")
    total_jobs = cursor.fetchone()["cnt"]

    print(f"\nğŸ“ˆ í†µê³„: ì˜ìƒ {video_count}ê°œ ë“±ë¡ | ë³‘í•© {total_jobs}ê±´ | ì—…ë¡œë“œ {uploaded_count}ê±´")

    conn.close()


def cmd_status_detail(job_id: int) -> None:
    """
    --status-detail ì˜µì…˜ ì²˜ë¦¬.

    íŠ¹ì • ì‘ì—…ì˜ ìƒì„¸ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.

    Args:
        job_id: merge_job ID
    """
    import json

    conn = init_database()

    cursor = conn.execute(
        """
        SELECT * FROM merge_jobs WHERE id = ?
        """,
        (job_id,),
    )
    job = cursor.fetchone()

    if not job:
        print(f"âŒ ì‘ì—… ID {job_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        conn.close()
        return

    print(f"\nğŸ“‹ ì‘ì—… ìƒì„¸ (ID: {job_id})\n")
    print("=" * 60)

    print(f"ğŸ“Œ ì œëª©: {job['title'] or '-'}")
    print(f"ğŸ“… ë‚ ì§œ: {job['date'] or '-'}")
    print(f"ğŸ“ ì¶œë ¥: {job['output_path']}")

    # ìƒíƒœ
    status = job["status"]
    status_icon = {
        "pending": "â³ ëŒ€ê¸°",
        "processing": "ğŸ”„ ì§„í–‰ ì¤‘",
        "completed": "âœ… ì™„ë£Œ",
        "failed": "âŒ ì‹¤íŒ¨",
    }.get(status, status)
    print(f"ğŸ“Š ìƒíƒœ: {status_icon}")

    # ê¸¸ì´/í¬ê¸°
    duration = job["total_duration_seconds"] or 0
    hours = int(duration // 3600)
    minutes = int((duration % 3600) // 60)
    seconds = int(duration % 60)
    if hours > 0:
        duration_str = f"{hours}ì‹œê°„ {minutes}ë¶„ {seconds}ì´ˆ"
    elif minutes > 0:
        duration_str = f"{minutes}ë¶„ {seconds}ì´ˆ"
    else:
        duration_str = f"{seconds}ì´ˆ"
    print(f"â±ï¸  ê¸¸ì´: {duration_str}")

    size_bytes = job["total_size_bytes"] or 0
    if size_bytes >= 1024 * 1024 * 1024:
        size_str = f"{size_bytes / (1024**3):.2f} GB"
    else:
        size_str = f"{size_bytes / (1024**2):.1f} MB"
    print(f"ğŸ’¾ í¬ê¸°: {size_str}")

    # YouTube
    if job["youtube_id"]:
        print(f"ğŸ¬ YouTube: https://youtu.be/{job['youtube_id']}")
    else:
        print("ğŸ¬ YouTube: ë¯¸ì—…ë¡œë“œ")

    # í´ë¦½ ì •ë³´
    clips_json = job["clips_info_json"]
    if clips_json:
        try:
            clips = json.loads(clips_json)
            print(f"\nğŸ“¹ í´ë¦½ ({len(clips)}ê°œ):")
            print("-" * 60)
            for i, clip in enumerate(clips, 1):
                name = clip.get("name", "-")
                clip_duration = clip.get("duration", 0)
                device = clip.get("device", "-")
                shot_time = clip.get("shot_time", "-")
                print(f"  {i}. {name}")
                print(f"     ê¸°ê¸°: {device} | ì´¬ì˜: {shot_time} | ê¸¸ì´: {clip_duration:.1f}s")
        except json.JSONDecodeError:
            pass

    print("=" * 60)
    conn.close()


def main() -> None:
    """CLI ì§„ì…ì ."""
    parser = create_parser()
    args = parser.parse_args()

    setup_logging(args.verbose)

    try:
        # --setup-youtube ì˜µì…˜ ì²˜ë¦¬ (ì„¤ì • ê°€ì´ë“œ)
        if args.setup_youtube:
            cmd_setup_youtube()
            return

        # --youtube-auth ì˜µì…˜ ì²˜ë¦¬ (ë¸Œë¼ìš°ì € ì¸ì¦)
        if args.youtube_auth:
            cmd_youtube_auth()
            return

        # --list-playlists ì˜µì…˜ ì²˜ë¦¬ (í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ëª©ë¡)
        if args.list_playlists:
            cmd_list_playlists()
            return

        # --reset-build ì˜µì…˜ ì²˜ë¦¬ (ë¹Œë“œ ê¸°ë¡ ì´ˆê¸°í™”)
        if args.reset_build is not None:
            cmd_reset_build(args.reset_build)
            return

        # --reset-upload ì˜µì…˜ ì²˜ë¦¬ (ì—…ë¡œë“œ ê¸°ë¡ ì´ˆê¸°í™”)
        if args.reset_upload is not None:
            cmd_reset_upload(args.reset_upload)
            return

        # --status ì˜µì…˜ ì²˜ë¦¬ (ì‘ì—… í˜„í™© ì¡°íšŒ)
        if args.status:
            cmd_status()
            return

        # --status-detail ì˜µì…˜ ì²˜ë¦¬ (ì‘ì—… ìƒì„¸ ì¡°íšŒ)
        if args.status_detail is not None:
            cmd_status_detail(args.status_detail)
            return

        # --upload-only ì˜µì…˜ ì²˜ë¦¬ (ì—…ë¡œë“œë§Œ)
        if args.upload_only:
            cmd_upload_only(args)
            return

        validated_args = validate_args(args)

        if validated_args.dry_run:
            # Dry run: ì‹¤í–‰ ê³„íšë§Œ ì¶œë ¥
            logger.info("Dry run mode - showing execution plan only")

            video_files = scan_videos(validated_args.targets)
            temp_dir = get_temp_dir()

            # ì¶œë ¥ ê²½ë¡œ ê³„ì‚°
            if validated_args.output:
                output_str = str(validated_args.output)
            else:
                output_filename = get_output_filename(validated_args.targets)
                output_dir = validated_args.output_dir or Path.cwd()
                output_str = str(output_dir / output_filename)

            print("\n=== Dry Run Execution Plan ===")
            print(f"Input targets: {[str(t) for t in validated_args.targets]}")
            print(f"Video files found: {len(video_files)}")
            for vf in video_files:
                print(f"  - {vf.path}")
            print(f"Output: {output_str}")
            print(f"Temp dir: {temp_dir}")
            print(f"Resume enabled: {not validated_args.no_resume}")
            print(f"Keep temp files: {validated_args.keep_temp}")
            print(f"Parallel workers: {validated_args.parallel}")
            print("=" * 30)
            return

        output_path = run_pipeline(validated_args)
        print("\nâœ… ì™„ë£Œ!")
        print(f"ğŸ“¹ ì¶œë ¥ íŒŒì¼: {output_path}")

        # --upload í”Œë˜ê·¸ ì²˜ë¦¬
        if validated_args.upload:
            print("\nğŸ“¤ YouTube ì—…ë¡œë“œ ì‹œì‘...")
            # DBì—ì„œ ìµœì‹  MergeJob ID ì¡°íšŒ
            merge_job_id = None
            title = None
            description = ""
            try:
                conn = init_database()
                repo = MergeJobRepository(conn)
                job = repo.get_latest()
                if job:
                    merge_job_id = job.id
                    title = job.title
                    description = job.summary_markdown or ""
                conn.close()
            except Exception as e:
                logger.warning(f"Failed to get merge job: {e}")

            # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
            playlist_ids = resolve_playlist_ids(args.playlist)

            upload_to_youtube(
                file_path=output_path,
                title=title,
                description=description,
                merge_job_id=merge_job_id,
                playlist_ids=playlist_ids,
                chunk_mb=args.upload_chunk,
            )

    except FileNotFoundError as e:
        logger.error(str(e))
        sys.exit(1)
    except ValueError as e:
        logger.error(str(e))
        sys.exit(1)
    except KeyboardInterrupt:
        logger.info("\nInterrupted by user")
        sys.exit(130)
    except Exception as e:
        logger.exception(f"Unexpected error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
