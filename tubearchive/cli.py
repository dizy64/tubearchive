"""CLI ì¸í„°í˜ì´ìŠ¤."""

import argparse
import json
import logging
import os
import shutil
import sys
import tempfile
from dataclasses import dataclass
from pathlib import Path

from tubearchive.core.detector import detect_metadata
from tubearchive.core.merger import Merger
from tubearchive.core.scanner import scan_videos
from tubearchive.core.transcoder import Transcoder
from tubearchive.database.repository import MergeJobRepository
from tubearchive.database.schema import init_database
from tubearchive.models.video import VideoFile
from tubearchive.utils.progress import MultiProgressBar
from tubearchive.utils.summary_generator import OutputInfo, save_summary

logger = logging.getLogger(__name__)

# í™˜ê²½ ë³€ìˆ˜
ENV_OUTPUT_DIR = "TUBEARCHIVE_OUTPUT_DIR"


def get_default_output_dir() -> Path | None:
    """í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê¸°ë³¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ ê°€ì ¸ì˜¤ê¸°."""
    env_dir = os.environ.get(ENV_OUTPUT_DIR)
    if env_dir:
        path = Path(env_dir)
        if path.is_dir():
            return path
        logger.warning(f"{ENV_OUTPUT_DIR}={env_dir} is not a valid directory")
    return None


def get_temp_dir() -> Path:
    """ì‹œìŠ¤í…œ ì„ì‹œ ë””ë ‰í† ë¦¬ ë‚´ tubearchive í´ë” ë°˜í™˜."""
    temp_base = Path(tempfile.gettempdir()) / "tubearchive"
    temp_base.mkdir(exist_ok=True)
    return temp_base


def check_output_disk_space(output_dir: Path, required_bytes: int) -> bool:
    """
    ì¶œë ¥ ë””ë ‰í† ë¦¬ ë””ìŠ¤í¬ ê³µê°„ í™•ì¸.

    Args:
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        required_bytes: í•„ìš”í•œ ë°”ì´íŠ¸ ìˆ˜

    Returns:
        ê³µê°„ì´ ì¶©ë¶„í•˜ë©´ True
    """
    usage = shutil.disk_usage(output_dir)
    if usage.free < required_bytes:
        logger.warning(
            f"Insufficient disk space: {usage.free / (1024**3):.1f}GB available, "
            f"{required_bytes / (1024**3):.1f}GB required"
        )
        return False
    return True


@dataclass
class ValidatedArgs:
    """ê²€ì¦ëœ CLI ì¸ì."""

    targets: list[Path]
    output: Path | None
    output_dir: Path | None
    no_resume: bool
    keep_temp: bool
    dry_run: bool


def create_parser() -> argparse.ArgumentParser:
    """
    CLI íŒŒì„œ ìƒì„±.

    Returns:
        argparse.ArgumentParser ì¸ìŠ¤í„´ìŠ¤
    """
    parser = argparse.ArgumentParser(
        prog="tubearchive",
        description="ë‹¤ì–‘í•œ ê¸°ê¸°ì˜ 4K ì˜ìƒì„ í‘œì¤€í™”í•˜ì—¬ ë³‘í•©í•©ë‹ˆë‹¤.",
        epilog="ì˜ˆì‹œ: tubearchive video1.mp4 video2.mov -o merged.mp4",
    )

    parser.add_argument(
        "targets",
        nargs="*",
        default=[],
        help="ì˜ìƒ íŒŒì¼ ë˜ëŠ” ë””ë ‰í† ë¦¬ (ê¸°ë³¸: í˜„ì¬ ë””ë ‰í† ë¦¬)",
    )

    parser.add_argument(
        "-o", "--output",
        type=str,
        default=None,
        help="ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸: merged_output.mp4)",
    )

    parser.add_argument(
        "--no-resume",
        action="store_true",
        help="Resume ê¸°ëŠ¥ ë¹„í™œì„±í™”",
    )

    parser.add_argument(
        "--keep-temp",
        action="store_true",
        help="ì„ì‹œ íŒŒì¼ ë³´ì¡´ (ë””ë²„ê¹…ìš©)",
    )

    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ì‹¤í–‰ ê³„íšë§Œ ì¶œë ¥ (ì‹¤ì œ ì‹¤í–‰ ì•ˆ í•¨)",
    )

    parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥",
    )

    parser.add_argument(
        "--output-dir",
        type=str,
        default=None,
        help=f"ì¶œë ¥ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬ (í™˜ê²½ë³€ìˆ˜: {ENV_OUTPUT_DIR})",
    )

    return parser


def validate_args(args: argparse.Namespace) -> ValidatedArgs:
    """
    CLI ì¸ì ê²€ì¦.

    Args:
        args: íŒŒì‹±ëœ ì¸ì

    Returns:
        ê²€ì¦ëœ ì¸ì

    Raises:
        FileNotFoundError: íŒŒì¼/ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°
    """
    # targets ê²€ì¦
    targets: list[Path] = []
    if not args.targets:
        targets = [Path.cwd()]
    else:
        for target in args.targets:
            path = Path(target)
            if not path.exists():
                raise FileNotFoundError(f"Target not found: {target}")
            targets.append(path)

    # output ê²€ì¦
    output: Path | None = None
    if args.output:
        output = Path(args.output)
        if not output.parent.exists():
            raise FileNotFoundError(f"Output directory not found: {output.parent}")

    # output_dir ê²€ì¦ (CLI ì¸ì > í™˜ê²½ ë³€ìˆ˜ > None)
    output_dir: Path | None = None
    if args.output_dir:
        output_dir = Path(args.output_dir)
        if not output_dir.is_dir():
            raise FileNotFoundError(f"Output directory not found: {args.output_dir}")
    else:
        output_dir = get_default_output_dir()

    return ValidatedArgs(
        targets=targets,
        output=output,
        output_dir=output_dir,
        no_resume=args.no_resume,
        keep_temp=args.keep_temp,
        dry_run=args.dry_run,
    )


def setup_logging(verbose: bool = False) -> None:
    """
    ë¡œê¹… ì„¤ì •.

    Args:
        verbose: ìƒì„¸ ë¡œê·¸ ì—¬ë¶€
    """
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
    )


def run_pipeline(validated_args: ValidatedArgs) -> tuple[Path, Path | None]:
    """
    ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰.

    Args:
        validated_args: ê²€ì¦ëœ ì¸ì

    Returns:
        (ìµœì¢… ì¶œë ¥ íŒŒì¼ ê²½ë¡œ, ìš”ì•½ íŒŒì¼ ê²½ë¡œ) íŠœí”Œ
    """
    # 1. íŒŒì¼ ìŠ¤ìº”
    logger.info("Scanning video files...")
    video_files = scan_videos(validated_args.targets)

    if not video_files:
        logger.error("No video files found")
        raise ValueError("No video files found")

    logger.info(f"Found {len(video_files)} video files")
    for vf in video_files:
        logger.info(f"  - {vf.path.name}")

    # 2. íŠ¸ëœìŠ¤ì½”ë”© (ì„ì‹œ íŒŒì¼ì€ /tmpì— ì €ì¥)
    temp_dir = get_temp_dir()
    logger.info(f"Using temp directory: {temp_dir}")
    logger.info("Starting transcoding...")
    transcoded_paths: list[Path] = []
    progress = MultiProgressBar(total_files=len(video_files))

    with Transcoder(temp_dir=temp_dir) as transcoder:
        for vf in video_files:
            progress.start_file(vf.path.name)

            def on_progress(percent: int) -> None:
                progress.update_file_progress(percent)

            output_path = transcoder.transcode_video(vf)
            transcoded_paths.append(output_path)
            progress.finish_file()

    # 3. ë³‘í•©
    logger.info("Merging videos...")
    output_path = validated_args.output or Path.cwd() / "merged_output.mp4"

    merger = Merger(temp_dir=temp_dir)
    final_path = merger.merge(transcoded_paths, output_path)

    logger.info(f"Final output: {final_path}")

    # 4. ìš”ì•½ ì •ë³´ ìƒì„±
    summary_path = generate_output_summary(
        video_files, final_path, validated_args.output_dir
    )

    # 5. ì„ì‹œ íŒŒì¼ ë° í´ë” ì •ë¦¬
    if not validated_args.keep_temp:
        logger.info("Cleaning up temporary files...")
        for temp_path in transcoded_paths:
            if temp_path.exists() and temp_path != final_path:
                temp_path.unlink()
                logger.debug(f"  Removed: {temp_path}")

        # ì„ì‹œ í´ë” ì‚­ì œ (ë¹„ì–´ìˆê±°ë‚˜ concat íŒŒì¼ë§Œ ë‚¨ì€ ê²½ìš°)
        if temp_dir.exists():
            try:
                shutil.rmtree(temp_dir)
                logger.info(f"Removed temp directory: {temp_dir}")
            except OSError as e:
                logger.warning(f"Failed to remove temp directory: {e}")

    return final_path, summary_path


def generate_output_summary(
    video_files: list[VideoFile],
    output_path: Path,
    output_dir: Path | None = None,
) -> Path | None:
    """
    ì¶œë ¥ ì˜ìƒ ìš”ì•½ ì •ë³´ ìƒì„± ë° DB ì €ì¥.

    Args:
        video_files: ì›ë³¸ ì˜ìƒ íŒŒì¼ ëª©ë¡
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        output_dir: ìš”ì•½ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬ (Noneì´ë©´ ì¶œë ¥ íŒŒì¼ê³¼ ê°™ì€ ë””ë ‰í† ë¦¬)

    Returns:
        ìš”ì•½ íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None
    """
    try:
        logger.info("Generating output summary...")

        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²°ì •
        summary_dir = output_dir or output_path.parent

        # ë””ìŠ¤í¬ ê³µê°„ í™•ì¸ (ìµœì†Œ 10MB ì—¬ìœ  í™•ì¸)
        if not check_output_disk_space(summary_dir, 10 * 1024 * 1024):
            logger.warning("Skipping summary generation due to insufficient disk space")
            return None

        # ê° ì˜ìƒì˜ duration ìˆ˜ì§‘
        video_durations: list[tuple[Path, float]] = []
        for vf in video_files:
            try:
                metadata = detect_metadata(vf.path)
                video_durations.append((vf.path, metadata.duration_seconds))
            except Exception as e:
                logger.warning(f"Failed to get duration for {vf.path}: {e}")
                video_durations.append((vf.path, 0.0))

        # OutputInfo ìƒì„±
        output_info = OutputInfo.from_video_files(video_durations, output_path)

        # ìš”ì•½ ë§ˆí¬ë‹¤ìš´ ì €ì¥
        summary_path = save_summary(output_info, summary_dir)
        logger.info(f"Summary saved: {summary_path}")

        # DBì— ì €ì¥
        save_merge_job_to_db(output_info, video_files)

        return summary_path

    except Exception as e:
        logger.warning(f"Failed to generate summary: {e}")
        return None


def save_merge_job_to_db(
    output_info: OutputInfo,
    video_files: list[VideoFile],
) -> None:
    """
    ë³‘í•© ì‘ì—… ì •ë³´ë¥¼ DBì— ì €ì¥.

    Args:
        output_info: ì¶œë ¥ ì •ë³´
        video_files: ì›ë³¸ ì˜ìƒ íŒŒì¼ ëª©ë¡
    """
    try:
        conn = init_database()
        repo = MergeJobRepository(conn)

        # í´ë¦½ ì •ë³´ JSON
        clips_json = json.dumps(
            [{"name": name, "duration": dur} for name, dur in output_info.clips],
            ensure_ascii=False,
        )

        # summary_path ê³„ì‚°
        actual_summary_path = (
            output_info.output_path.parent / f"{output_info.output_path.stem}_summary.md"
        )

        repo.create(
            output_path=output_info.output_path,
            video_ids=[],  # í˜„ì¬ video_ids ì¶”ì  ì•ˆ í•¨ (ë‹¨ìˆœí™”)
            title=output_info.title,
            date=output_info.date,
            total_duration_seconds=output_info.total_duration,
            total_size_bytes=output_info.total_size,
            clips_info_json=clips_json,
            summary_path=actual_summary_path,
        )
        conn.close()
        logger.debug("Merge job saved to database")

    except Exception as e:
        logger.warning(f"Failed to save merge job to DB: {e}")


def main() -> None:
    """CLI ì§„ì…ì ."""
    parser = create_parser()
    args = parser.parse_args()

    setup_logging(args.verbose)

    try:
        validated_args = validate_args(args)

        if validated_args.dry_run:
            # Dry run: ì‹¤í–‰ ê³„íšë§Œ ì¶œë ¥
            logger.info("Dry run mode - showing execution plan only")

            video_files = scan_videos(validated_args.targets)
            temp_dir = get_temp_dir()
            output_dir_str = (
                str(validated_args.output_dir) if validated_args.output_dir else "(ì¶œë ¥ íŒŒì¼ ìœ„ì¹˜)"
            )

            print("\n=== Dry Run Execution Plan ===")
            print(f"Input targets: {[str(t) for t in validated_args.targets]}")
            print(f"Video files found: {len(video_files)}")
            for vf in video_files:
                print(f"  - {vf.path}")
            print(f"Output: {validated_args.output or 'merged_output.mp4'}")
            print(f"Output dir: {output_dir_str}")
            print(f"Temp dir: {temp_dir}")
            print(f"Resume enabled: {not validated_args.no_resume}")
            print(f"Keep temp files: {validated_args.keep_temp}")
            print("=" * 30)
            return

        output_path, summary_path = run_pipeline(validated_args)
        print("\nâœ… ì™„ë£Œ!")
        print(f"ğŸ“¹ ì¶œë ¥ íŒŒì¼: {output_path}")
        if summary_path:
            print(f"ğŸ“ ìš”ì•½ íŒŒì¼: {summary_path}")

    except FileNotFoundError as e:
        logger.error(str(e))
        sys.exit(1)
    except ValueError as e:
        logger.error(str(e))
        sys.exit(1)
    except KeyboardInterrupt:
        logger.info("\nInterrupted by user")
        sys.exit(130)
    except Exception as e:
        logger.exception(f"Unexpected error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
